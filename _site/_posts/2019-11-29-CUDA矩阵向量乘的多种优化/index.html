<!DOCTYPE html>
<html>

<head>
  
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>CUDA矩阵向量乘的多种优化 | wu-kan</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="CUDA矩阵向量乘的多种优化" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="实验简介" />
<meta property="og:description" content="实验简介" />
<link rel="canonical" href="http://localhost:4000/_posts/2019-11-29-CUDA%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E7%9A%84%E5%A4%9A%E7%A7%8D%E4%BC%98%E5%8C%96/" />
<meta property="og:url" content="http://localhost:4000/_posts/2019-11-29-CUDA%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E7%9A%84%E5%A4%9A%E7%A7%8D%E4%BC%98%E5%8C%96/" />
<meta property="og:site_name" content="wu-kan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-11-29T00:00:00+08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://localhost:4000/_posts/2019-11-29-CUDA%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E7%9A%84%E5%A4%9A%E7%A7%8D%E4%BC%98%E5%8C%96/","headline":"CUDA矩阵向量乘的多种优化","dateModified":"2019-11-29T00:00:00+08:00","datePublished":"2019-11-29T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/_posts/2019-11-29-CUDA%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E7%9A%84%E5%A4%9A%E7%A7%8D%E4%BC%98%E5%8C%96/"},"description":"实验简介","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  
  
  <meta
  name="viewport"
  content="width=device-width, initial-scale=1.0, maximum-scale=1"
/>
<meta
  http-equiv="content-type"
  content="text/html; charset=utf-8"
/>
<link
  rel="alternate"
  href="/feed.xml"
  title="RSS"
  type="application/rss+xml"
/>

  
  <link
  rel="apple-touch-icon-precomposed"
  href="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=320"
/>
<link
  rel="shortcut
  icon"
  href="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=32"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/combine/gh/poole/lanyon@v1.1.0/public/css/poole.min.css,gh/poole/lanyon@v1.1.0/public/css/lanyon.min.css"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/Dreamer-Paul/Pio@2.4/static/pio.min.css"
/>
<script
  async="async"
  src="https://cdn.jsdelivr.net/combine/gh/Dreamer-Paul/Pio@2.4/static/l2d.min.js,gh/Dreamer-Paul/Pio@2.4/static/pio.min.js"
  onload='
      let pio_container = document.createElement("div");
      pio_container.classList.add("pio-container");
      pio_container.classList.add("right");
      pio_container.style.bottom = "-2rem";
      pio_container.style.zIndex = "1";
      document.body.insertAdjacentElement("beforeend", pio_container);
      let pio_action = document.createElement("div");
      pio_action.classList.add("pio-action");
      pio_container.insertAdjacentElement("beforeend", pio_action);
      let pio_canvas = document.createElement("canvas");
      pio_canvas.id = "pio";
      pio_canvas.style.width = "14rem";
      pio_canvas.width = "600";
      pio_canvas.height = "800";
      pio_container.insertAdjacentElement("beforeend", pio_canvas);
      let pio = new Paul_Pio({
        "mode": "fixed",
        "hidden": true,
        "night": "for(let i=7; i<16; ++i) if(document.body.classList.contains(`theme-base-0`+i.toString(16))) { document.body.classList.remove(`theme-base-0`+i.toString(16)); document.body.classList.add(`theme-base-0`+((i-6)%9+7).toString(16)); break; }",
        "content": {
          "link": ["https://jekyll-theme-WuK.wu-kan.cn"],
          "skin": ["要换成我的朋友吗？", "让她放个假吧~"],
          "hidden": true,
          "custom": [{
            "selector": "a",
            "type": "link",
          }, {
            "selector": ".sidebar-toggle",
            "text": "打开侧边栏叭~"
          }, {
            "selector": ".effect-info",
            "text": "哇，你发现了什么！"
          }, {
            "selector": "#sidebar-search-input",
            "text": "想搜索什么呢？很多干货哦！"
          }, {
            "selector": "#toc",
            "text": "这是目录~"
          }, {
            "selector": ".page-title",
            "text": "这是标题~"
          }, {
            "selector": ".v",
            "text": "评论没有审核，要对自己的发言负责哦~"
          }]
        },
        "model": [
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/33/model.2018.bls-winter.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/platelet-2/model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/xiaomai/xiaomai.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/mashiro/seifuku.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/Violet/14.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/Kobayaxi/Kobayaxi.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/mikoto/mikoto.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/uiharu/uiharu.model.json"]
      });'
></script>

  
  <script
  src='https://zz.bdstatic.com/linksubmit/push.js'
  async="async"
></script>

  
  <script
  async="async"
  src="https://www.googletagmanager.com/gtag/js?id=UA-163543967-1"
  onload="
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-163543967-1');"
></script>

  
  <style>
  .wrap {
    transition-property: all;
    transition-duration: .3s;
    transition-timing-function: ease-in-out;
    min-height: 100%;
    display: inline-block;
    background-size: 100% auto;
    background-position: 0% 0%;
    background-repeat: no-repeat;
    background-attachment: fixed;
    background-image: url(https://Mizuno-Ai.wu-kan.cn/pixiv/74559485_p1.webp);
  }
  @media (min-aspect-ratio: 2400/1850) {
    .wrap {
      background-image: url(https://Mizuno-Ai.wu-kan.cn/pixiv/71932901_p0.webp);
    }
  }
  .sidebar-overlay #sidebar-checkbox:checked ~ .wrap {
    width: calc(100% - 14rem);
    background-size: calc(100% - 14rem) auto;
    left: 14rem;
  }
  .layout-reverse.sidebar-overlay #sidebar-checkbox:checked ~ .wrap {
    left: 0;
  }
</style>

  
  <style>
  html,
  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  .sidebar {
    font-family: PingFang SC, Menlo, Monaco, "Courier New", Microsoft JhengHei, monospace;
  }
</style>

  
  <style>
  img {
    display: inline-block;
    margin: 0;
  }
</style>

  
  <style>
  ::-webkit-scrollbar {
    width: 4px;
    height: 4px;
  }
  ::-webkit-scrollbar-thumb {
    background-image: linear-gradient(45deg, Cyan 0%, Magenta 50%, Yellow 100%);
  }
</style>

  
  <style>
  ::selection {
    color: White;
    background: Black;
  }
</style>

  
</head>

<body
  class="theme-base-07 layout-reverse sidebar-overlay">
  
  
  
  <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
  <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"
     />
  <!-- Toggleable sidebar -->
  <div class="sidebar" id="sidebar">
    
    <div class="sidebar-item">
      <div class="effect effect-right_to_left">
        <img class="effect-img" src="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=320" alt="img" />
        <div class="effect-info">
          SYSU超算17级在读<br/>
永远喜欢水野爱<br/>
田宫例四驱车<br/>
ASC<br/>
<a href="mailto:i@wu-kan.cn">
  <i class="fas fa-envelope"></i>
</a>
<a href="https://github.com/wu-kan">
  <i class="fab fa-github"></i>
</a>
<a href="https://codeforces.com/profile/WuK">
  <i class="fas fa-chart-bar"></i>
</a>
<a href="https://vjudge.net/user/WuK">
  <i class="fas fa-smile"></i>
</a>
<a href="https://www.zhihu.com/people/wu.kan/activities">
  <i class="fab fa-zhihu"></i>
</a>
<iframe
  src="https://music.163.com/outchain/player?type=0&id=155059595&auto=0&height=32"
  width=100%
  height=52
  frameborder="no"
  border="0"
  marginwidth="0"
  marginheight="0"
></iframe>

        </div>
      </div>
    </div>
    
    <nav class="sidebar-nav">
      
      <a class="sidebar-nav-item" href="/">
        <i class="fas fa-home fa-fw"></i> 首页
      </a>
      
      <a class="sidebar-nav-item" href="/comments/">
        <i class="fas fa-comments fa-fw"></i> 留言
      </a>
      
      <a class="sidebar-nav-item" href="/tags/">
        <i class="fas fa-tags fa-fw"></i> 标签
      </a>
      
      <a class="sidebar-nav-item" href="/archive/">
        <i class="fas fa-archive fa-fw"></i> 归档
      </a>
      
      <a class="sidebar-nav-item" href="/merger/">
        <i class="fas fa-coffee fa-fw"></i> 打赏
      </a>
      
    </nav>
    <div class="sidebar-item">
      
      <div>
        <style>
  #sidebar-search-input {
    background: none;
    border: none;
    color: White;
    width: 100%;
  }
  #sidebar-search-results-container {
    overflow: auto auto;
    max-height: 50vh;
  }
</style>
<input
  id="sidebar-search-input"
  placeholder="搜索博文"
/>
<ol
  id="sidebar-search-results-container"
></ol>
<script
  src='https://cdn.jsdelivr.net/npm/simple-jekyll-search/dest/simple-jekyll-search.min.js'
  async='async'
  onload='
    SimpleJekyllSearch({
      json: "/assets/simple-jekyll-search/search.json",
      searchInput: document.getElementById("sidebar-search-input"),
      resultsContainer: document.getElementById("sidebar-search-results-container"),
      searchResultTemplate: `<li><a href="{url}">{title}</a></li>`,
      limit: 999,
      fuzzy: true
    })'
></script>

      </div>
      
      
      <style>
  .sidebar-checkbox {
    display: none;
  }
  .sidebar-toggle {
    position: fixed;
  }
</style>

      
      <style>
  .effect {
    margin: 1rem;
    perspective: 900px;
  }
  .effect-info {
    text-align: center;
    backface-visibility: hidden;
    position: absolute;
    top: 0;
    transform-style: preserve-3d;
  }
  .effect-img {
    z-index: 11;
    width: 100%;
    height: 100%;
    position: relative;
    transition: all 0.5s ease-in-out;
  }
  .effect-img:before {
    position: absolute;
    display: block;
  }
  .effect-right_to_left .effect-img {
    transform-origin: 0% 50%;
  }
  .effect-right_to_left:hover .effect-img {
    transform: rotate3d(0, 1, 0, -180deg);
  }
</style>

      
      <style>
  #toc {
    overflow: auto auto;
    max-height:50vh;
  }
</style>
<aside id="toc">
  目录
</aside>
<script
  defer='defer'
  src='https://cdn.jsdelivr.net/npm/html-contents/html-contents.min.js'
  onload="htmlContents('#toc', {listType: 'o', filter: function(arr) {return !arr.matches('.masthead-title')}})"
></script>

      
      <div>
  <i class="fas fa-cog fa-spin fa-fw"></i>
  <span id="run_time_day">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>天
  <span id="run_time_hour">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>时
  <span id="run_time_minute">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>分
  <span id="run_time_second">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>秒
  <script>
    setInterval(function (BirthDay) {
      function setzero(i) {
        if (i < 10) return "0" + i;
        return i;
      }
      BirthDay = new Date(BirthDay);
      today = new Date();
      timeold = (today.getTime() - BirthDay.getTime());
      sectimeold = timeold / 1000;
      secondsold = Math.floor(sectimeold);
      msPerDay = 24 * 60 * 60 * 1000;
      e_daysold = timeold / msPerDay;
      daysold = Math.floor(e_daysold);
      e_hrsold = (e_daysold - daysold) * 24;
      hrsold = Math.floor(e_hrsold);
      e_minsold = (e_hrsold - hrsold) * 60;
      minsold = Math.floor((e_hrsold - hrsold) * 60);
      seconds = Math.floor((e_minsold - minsold) * 60);
      document.getElementById("run_time_day").innerHTML = daysold;
      document.getElementById("run_time_hour").innerHTML = setzero(hrsold);
      document.getElementById("run_time_minute").innerHTML = setzero(minsold);
      document.getElementById("run_time_second").innerHTML = setzero(seconds);
    }, 1000, "10/04/2017 11:03:56") // 这是我第一篇CSDN博客的时间
  </script>
</div>

      
      <div>
  <div>
    <i class="fas fa-eye fa-fw"></i>
    <span id="busuanzi_value_page_pv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>次
  </div>
  <div>
    <i class="fas fa-paw fa-fw"></i>
    <span id="busuanzi_value_site_pv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>枚
  </div>
  <div>
    <i class="fas fa-user-friends fa-fw"></i>
    <span id="busuanzi_value_site_uv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>人
  </div>
  <script
    src='https://cdn.jsdelivr.net/npm/busuanzi'
    async='async'
  ></script>
</div>

      
      <div>
  <i class="fas fa-copyright fa-fw"></i>
  2017-2020 WuK
</div>

      
      <div>
  <i class="fas fa-thumbs-up fa-fw"></i>
  <a href="https://jekyll-theme-WuK.wu-kan.cn">
    jekyll-theme-WuK
  </a>
</div>

      
      <div>
  <i class="fas fa-info-circle fa-fw"></i>
  <a href="http://beian.miit.gov.cn">
    粤ICP备20024947号
  </a>
</div>

      
      
    </div>
  </div>
  <!-- Wrap is the content to shift when toggling the sidebar. We wrap the content to avoid any CSS collisions with our real content. -->
  
  <div class="wrap">
    
<style>
  pre {
    max-height: 50vh;
    overflow: auto;
  }
</style>


<style>
  @media (min-width: 56em) {
    .container {
      max-width: 66.6%;
    }
  }
</style>


<style>
  .masthead,
  .container.content {
    padding-top: 1rem;
    padding-bottom: 1rem;
    box-shadow: 0 0 .75rem rgba(0, 0, 0, 0.1);
    background-color: rgba(255, 255, 255, 0.95);
    animation-duration: 2s;
    animation-name: fadeIn;
  }
  @keyframes fadeIn {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }
</style>


<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/combine/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.css,npm/prismjs/plugins/toolbar/prism-toolbar.min.css,gh/PrismJS/prism-themes@1955cfef6953b3a59e66016e8a1e016b45d6cc79/themes/prism-nord.min.css"
/>
<script
  src="https://cdn.jsdelivr.net/combine/npm/prismjs/components/prism-core.min.js,npm/prismjs/plugins/autoloader/prism-autoloader.min.js,npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js,npm/prismjs/plugins/toolbar/prism-toolbar.min.js"
  defer="defer"
  onload='
    Prism.plugins.autoloader.languages_path = "https:\/\/cdn.jsdelivr.net/npm/prismjs/components/";
    for(let x=document.getElementsByTagName("pre"), i=0;i<x.length;i++)
    {
      x[i].classList.add("line-numbers");
    }
    Prism.plugins.toolbar.registerButton("select-code", function (env) {
      let button = document.createElement("button");
      button.innerHTML = "select this " + env.language;
      button.addEventListener("click", function () {
        if (document.body.createTextRange) {
          let range = document.body.createTextRange();
          range.moveToElementText(env.element);
          range.select();
        } else if (window.getSelection) {
          let selection = window.getSelection();
          let range = document.createRange();
          range.selectNodeContents(env.element);
          selection.removeAllRanges();
            selection.addRange(range);
        }
      });
      return button;
    })'
></script>


<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"
/>
<script
  src="https://cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/mathtex-script-type.min.js,npm/katex/dist/contrib/auto-render.min.js"
  defer="defer"
  onload='renderMathInElement(document.body, { delimiters: [{ left: "$", right: "$", display: false }] })'
></script>


<style>
  pre.language-mermaid,
  code.language-mermaid {
    display: none;
  }
</style>
<script
  src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"
  defer="defer"
  onload='
  for(let x=document.getElementsByClassName("language-mermaid"), i=0;i<x.length;i++)
    if(x[i].nodeName=="CODE")
    {
      let m = document.createElement("div");
      m.classList.add("mermaid");
      m.textContent = x[i].textContent;
      x[i].parentNode.insertAdjacentElement("beforebegin", m);
    }'
></script>



<div class="masthead">
  <h3 class="container masthead-title">
    
    CUDA矩阵向量乘的多种优化
    <a href="http://localhost:4000/" title="Home">
      <small>
        wu-kan
      </small>
    </a>
    
  </h3>
</div>

<div class="container content">
  <div class="post">
  <span class="post-date">
    
    <i class="fas fa-calendar-day fa-fw"></i>
    29 Nov 2019
    
    
    <i class="fas fa-file-word fa-fw"></i>
    11105字
    
    
    <i class="fas fa-clock fa-fw"></i>
    38分
    
    
    
    <i class="fas fa-tag fa-fw"></i>
    高性能计算
    
    <br/>
<i class="fas fa-coffee fa-fw"></i>
<a href="/merger/">如果这篇博客帮助到你，可以请我喝一杯咖啡~</a>
<br/>
<i class="fab fa-creative-commons-by fa-fw"></i>
<a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">CC BY 4.0</a>（除特别声明或转载文章外）

    
  </span>
  <h2 id="实验简介">实验简介</h2>

<p>使用下面一种或多种优化方法完成 CUDA 的矩阵向量乘法$y=A\times x$,其中$A$是$2^{14}\times 2^{14}$的方阵，$x$为$2^{14}$维向量。假设矩阵$A$的元素为$a_{i,j}=i-0.1\times j+1$，向量$x$的元素为$b_i=\log\sqrt{i\times i-i+2}$。</p>

<ul>
  <li>使用 global memory</li>
  <li>使用合并访存</li>
  <li>使用 constant memory 存放向量</li>
  <li>使用 shared memory 存放向量和矩阵</li>
  <li>使用 warp 直接访问寄存器</li>
  <li>使用 <code>cublasSgemv</code></li>
</ul>

<h2 id="实验环境">实验环境</h2>

<p>实验在老师提供的计算集群的一个节点上进行。单节点的显卡配置如下：</p>

<pre><code class="language-bash">$ nvdia-smi
Mon Dec  2 08:38:49 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0    24W / 250W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre>

<h2 id="实验原理">实验原理</h2>

<p>优化 CUDA 架构上的程序，一般从以下几个方面考虑：</p>

<ul>
  <li>选择好的并行算法，发掘更多的数据并行性</li>
  <li>保持 SM 尽可能忙碌，尽量利用所有的 SM 参与计算
    <ul>
      <li>加大数据量</li>
      <li>减小线程块大小</li>
    </ul>
  </li>
  <li>优化存储器的使用
    <ul>
      <li>全局存储器合并访问</li>
      <li>使用更快的 constant memory 或 shared memory</li>
    </ul>
  </li>
  <li>使用一些已有的库，如<code>&lt;cuBlas_v2.h&gt;</code></li>
</ul>

<h2 id="实验过程">实验过程</h2>

<p>由于都是 CUDA 架构上的核函数对比性能，下面的计时都只测了用于核函数计算的时间，而不包含数据拷贝的部分（否则运行时间都在 300ms 左右，基本上都是拷贝的时间而没有参考价值了）。当然，由于没有计入拷贝等预处理的时间，那些需要计算转置（列优先）或者预读取的算法在这里会有优势一些。</p>

<h3 id="使用-global-memory">使用 global memory</h3>

<p>这是最基础的矩阵向量乘法。这里假设线程块都是一维组织的，每个 CUDA 线程计算矩阵的一行与向量乘积，这样各线程之间没有读写冲突，不需要使用原子操作。</p>

<pre><code class="language-cpp">void __global__ wkSgemvGlobalMemory(
	const float *Ar, //行优先形式，下同
	const float *x,
	float *y,
	const size_t m, //A的行数
	const size_t n) //A的列数
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &lt; m)
	{
		float res = 0; //将结果先存在寄存器里，减少对向量y的访存
		for (size_t j = 0; j &lt; n; ++j)
			res += Ar[i * n + j] * x[j];
		y[i] = res;
	}
}
</code></pre>

<p>运行时间为<code>4.694240ms</code>。</p>

<h3 id="使用合并访存">使用合并访存</h3>

<p>所谓合并访存，指的是相邻的线程访问段对齐的地址。比如在之前的代码中，<code>j == 0</code>时线程 0 访问<code>Ar[0]</code>，线程 1 访问<code>Ar[nCol]</code>，线程 2 访问<code>Ar[2 * nCol]</code>…它们并不相邻，因此不满足合并访问的要求。在这里我们把原来的行优先矩阵$A$转换成列优先表示形式（即行优先下的转置$A^T$），此时<code>j == 0</code>时线程 0 访问<code>Ac[0]</code>，线程 1 访问<code>Ac[1]</code>，线程 2 访问<code>Ac[2]</code>…此时满足了合并访问的要求。</p>

<pre><code class="language-cpp">void __global__ wkSgemvGlobalMemoryAlign(
	const float *Ac, //列优先形式，下同
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &lt; m)
	{
		float res = 0;
		for (size_t j = 0; j &lt; n; ++j)
			res += Ac[j * m + i] * x[j];
		y[i] = res;
	}
}
</code></pre>

<p>运行时间为<code>1.551584ms</code>，性能提高了将近三倍，充分说明了合并访存的重要性。</p>

<h3 id="使用-constant-memory-存放向量">使用 constant memory 存放向量</h3>

<p>注意到向量在计算过程中不会改变，且每个线程访问相同地址，因此考虑把它放在 constant memory 中。</p>

<p>NVIDIA 硬件提供了 64KB 的常量内存，并且常量内存采用了不同于标准全局内存的处理方式。在这里我们大小为$2^{14}$的单精度浮点数向量$x$大小恰好为 64KB，正好可以完整保存。如果向量超过了 constant memory 的 64KB 上限，那就需要分批进行，多次传输和启动内核。</p>

<pre><code class="language-cpp">float __constant__ d_cx[(1 &lt;&lt; 16) / sizeof(float)]; //64KB
void __global__ wkSgemvConstantMemory(
	const float *Ac,
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &lt; m)
	{
		float res = 0;
		for (size_t j = 0; j &lt; n; ++j)
			res += Ac[j * m + i] * d_cx[j];
		y[i] = res;
	}
}
</code></pre>

<p>运行时间为<code>1.516992ms</code>，在上一步的基础上略微提高。使用常量内存可以提升运算性能的原因主要有两个：</p>

<ol>
  <li>对常量内存的单次读操作可以广播到同个半线程束的其他$15$个线程，这种方式产生的内存流量只是使用全局内存时的$\frac{1}{16}$。</li>
  <li>硬件将主动把常量数据缓存在 GPU 上。在第一次从常量内存的某个地址上读取后，当其他半线程束请求同一个地址时，那么将命中缓存，这同样减少了额外的内存流量。</li>
</ol>

<h3 id="使用-shared-memory-存放向量和矩阵">使用 shared memory 存放向量和矩阵</h3>

<p>对于 block 内内存来说，向量都是共享的，因此我们可以使用比 constant memory 更快的 shared memory 来存储，此时相比较使用常量内存，我们免掉了向量比较大的时候多次数据拷贝和启动核函数的开销，也没有使用全局变量，增加了代码的可扩展性。当然，shared memory 更小（48K），因此需要对向量进行分块处理。</p>

<p>另外需要更正的一个问题是，并不需要使用 shared memory 去存矩阵，因为在这个矩阵向量乘的过程中，每个矩阵元素只被访问了一次。此外，shared memory 的大小也并不足以存下完整的矩阵（甚至是向量）。</p>

<pre><code class="language-cpp">template &lt;size_t reduce_size&gt;
void __global__ wkSgemvSharedMemory(
	const float *Ac,
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	extern float __shared__ sx[];
	const size_t
		i = blockDim.x * blockIdx.x + threadIdx.x,
		jBegLast = n / reduce_size * reduce_size;
	float res = 0;
	for (size_t jBeg = 0; jBeg &lt; jBegLast; jBeg += reduce_size)
	{
		__syncthreads(); //防止有的进程还在读sx
		sx[threadIdx.x] = x[jBeg + threadIdx.x];
		__syncthreads();
		if (i &lt; m)
			for (size_t j = 0; j &lt; reduce_size; ++j) //能够自动展开
				res += Ac[(j + jBeg) * m + i] * sx[j];
	}
	{
		__syncthreads(); //防止有的进程还在读sx
		if (jBegLast + threadIdx.x &lt; n)
			sx[threadIdx.x] = x[jBegLast + threadIdx.x];
		__syncthreads();
		if (i &lt; m)
			for (size_t j = 0; j &lt; n - jBegLast; ++j) //不能自动展开
				res += Ac[(j + jBegLast) * m + i] * sx[j];
	}
	if (i &lt; m)
		y[i] = res;
}
</code></pre>

<p>运行时间为<code>1.400672ms</code>。注意这里我们将循环展开了，好处是减少了核函数运行时的分支。如果不展开的话，其运行时间将退化到比之前的还慢。</p>

<h4 id="使用-shuffle">使用 shuffle</h4>

<pre><code class="language-cpp">template &lt;size_t warp_size&gt;
void __global__ wkSgemvWarp(
	const float *Ac,
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	const size_t
		i = blockDim.x * blockIdx.x + threadIdx.x,
		lane_id = i % warp_size,
		jBegLast = n / warp_size * warp_size;
	float res = 0;
	for (size_t jBeg = 0; jBeg &lt; jBegLast; jBeg += warp_size)
	{
		const float val = x[jBeg + lane_id];
		for (size_t j = 0; j &lt; warp_size; ++j) //能够自动展开
			res += Ac[(j + jBeg) * m + i] * __shfl_sync(0xffffffff, val, j, warp_size);
	}
	{
		const float val = jBegLast + lane_id &lt; n ? x[jBegLast + lane_id] : 0;
		for (size_t j = 0; j &lt; n - jBegLast; ++j) //不能自动展开
			res += Ac[(j + jBegLast) * m + i] * __shfl_sync(0xffffffff, val, j, warp_size);
	}
	if (i &lt; m)
		y[i] = res;
}
</code></pre>

<p>运行时间<code>1.594368ms</code>，反而有一定的下降。分析一下原因：老师集群上的显卡性能过于强悍（在今年十一月 SC 超算大会刚发布 Tesla V100S 前，Tesla V100 一直都是市面能买到的最强算力），内存读写性能比以往的显卡都要强很多，因此对本来已经很快的 shared memory 的优化效果没有那么明显了，而由于<code>warp_size</code>小于<code>reduce_size</code>导致循环分支次数却比上一步多，效果变差。</p>

<h3 id="使用-cublas_v2h">使用 <code>&lt;cublas_v2.h&gt;</code></h3>

<p>该函数的官方文档见<a href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-lt-t-gt-gemv">https://docs.nvidia.com/cuda/cublas/index.html#cublas-lt-t-gt-gemv</a>。下面是传入行优先矩阵的调用。要尤其注意的是，cublas库为了与FORTRAN中的接口保持一致，默认的稠密矩阵是按照列优先方法存储的，因此对于行优先存储的形式反而要标记转置。</p>

<pre><code class="language-cpp">cublasSgemv(
	wk_cublas_handle,
	CUBLAS_OP_T,
	m,
	n,
	&amp;alpha,
	d_Ar,
	m,
	d_x,
	1,
	&amp;beta,
	d_y,
	1);
</code></pre>

<p>运行时间<code>1.863520ms</code>。下面是传入列优先矩阵的调用。</p>

<pre><code class="language-cpp">cublasSgemv(
	wk_cublas_handle,
	CUBLAS_OP_N,
	m,
	n,
	&amp;alpha,
	d_Ac,
	m,
	d_x,
	1,
	&amp;beta,
	d_y,
	1);
</code></pre>

<p>运行时间<code>1.381888ms</code>。（艹，我做了这半天的优化结果还没它快）</p>

<h3 id="sgemvo12727"><code>Sgemv.o12727</code></h3>

<p>分别是上面几种方法函数的运行时间。</p>

<pre><code class="language-bash">4.694240ms
1.551584ms
1.516992ms
1.400672ms
1.594368ms
1.863520ms
1.381888ms
</code></pre>

<p>可以看到，由于现在的硬件性能已经大大强于数年前，做存储器的优化效果已经比较小（并不是说没有，只是甚至已经小于多次循环跳转的开销了）。因此，对这个问题来说，最主要的是要选一个优秀的并行算法，再对程序代码做好访存分析和优化。</p>

<p>当然也不是说存储器结构就不再重要，还是要具体问题具体分析。上面很多算法都是要对矩阵或者向量进行预处理的，而并没有把对应的代价（时间、内存空间、可扩展性等）计入在内，实际上在运用到生产环境的时候这些仍然是必须要考虑的。最后，虽然前面的代码还没有调库跑得快，实际上还是有优化余地的，比如：</p>

<ul>
  <li>使用<code>#pragma unroll</code>进行循环展开。
    <ul>
      <li>我在测试的时候用这种方法一度将<code>wkSgemvConstantMemory</code>优化至<code>1.35ms</code>，但是这种方法实际上是面向硬件和数据本身的（需要提前知道有多少数据被优化，才能确定展开多少次是安全的），在真正的生产环境中可移植性不够高，我不是非常喜欢。</li>
    </ul>
  </li>
  <li>多路启动，每个线程负责多个向量元素，可以减少调度时开销。
    <ul>
      <li>不喜欢的理由同上。</li>
    </ul>
  </li>
</ul>

<p>总之结论就是，在实际生产力环境中还是直接调库来的省事，库中的黑科技代码在绝大多数情况下都是要优秀于自己写的代码的。当然，自己手动做过这个实验也可以帮助我们对库的代码做进了一步的理解，比如列优先矩阵的向量乘法为什么优秀于行优先。</p>

<h3 id="sgemvpbs"><code>Sgemv.pbs</code></h3>

<p>调度脚本。</p>

<pre><code class="language-bash">#PBS -N Sgemv
#PBS -l nodes=1:ppn=32:gpus=1
#PBS -j oe
#PBS -q gpu
source /public/software/profile.d/cuda10.0.sh
cd $PBS_O_WORKDIR
nvcc Sgemv.cu -run -lcublas
</code></pre>

<h3 id="sgemvcu"><code>Sgemv.cu</code></h3>

<p>完整代码。</p>

<pre><code class="language-cpp">#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include &lt;cuda_runtime.h&gt;
#include &lt;cublas_v2.h&gt;
void __global__ wkSgemvGlobalMemory(
	const float *Ar, //行优先形式，下同
	const float *x,
	float *y,
	const size_t m, //A的行数
	const size_t n) //A的列数
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &lt; m)
	{
		float res = 0; //将结果先存在寄存器里，减少对向量y的访存
		for (size_t j = 0; j &lt; n; ++j)
			res += Ar[i * n + j] * x[j];
		y[i] = res;
	}
}
void __global__ wkSgemvGlobalMemoryAlign(
	const float *Ac, //列优先形式，下同
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &lt; m)
	{
		float res = 0;
		for (size_t j = 0; j &lt; n; ++j)
			res += Ac[j * m + i] * x[j];
		y[i] = res;
	}
}
float __constant__ d_cx[(1 &lt;&lt; 16) / sizeof(float)]; //64KB
void __global__ wkSgemvConstantMemory(
	const float *Ac,
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &lt; m)
	{
		float res = 0;
		for (size_t j = 0; j &lt; n; ++j)
			res += Ac[j * m + i] * d_cx[j];
		y[i] = res;
	}
}
template &lt;size_t reduce_size&gt;
void __global__ wkSgemvSharedMemory(
	const float *Ac,
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	extern float __shared__ sx[];
	const size_t
		i = blockDim.x * blockIdx.x + threadIdx.x,
		jBegLast = n / reduce_size * reduce_size;
	float res = 0;
	for (size_t jBeg = 0; jBeg &lt; jBegLast; jBeg += reduce_size)
	{
		__syncthreads(); //防止有的进程还在读sx
		sx[threadIdx.x] = x[jBeg + threadIdx.x];
		__syncthreads();
		if (i &lt; m)
			for (size_t j = 0; j &lt; reduce_size; ++j) //能够自动展开
				res += Ac[(j + jBeg) * m + i] * sx[j];
	}
	{
		__syncthreads(); //防止有的进程还在读sx
		if (jBegLast + threadIdx.x &lt; n)
			sx[threadIdx.x] = x[jBegLast + threadIdx.x];
		__syncthreads();
		if (i &lt; m)
			for (size_t j = 0; j &lt; n - jBegLast; ++j) //不能自动展开
				res += Ac[(j + jBegLast) * m + i] * sx[j];
	}
	if (i &lt; m)
		y[i] = res;
}
template &lt;size_t warp_size&gt;
void __global__ wkSgemvWarp(
	const float *Ac,
	const float *x,
	float *y,
	const size_t m,
	const size_t n)
{
	const size_t
		i = blockDim.x * blockIdx.x + threadIdx.x,
		lane_id = i % warp_size,
		jBegLast = n / warp_size * warp_size;
	float res = 0;
	for (size_t jBeg = 0; jBeg &lt; jBegLast; jBeg += warp_size)
	{
		const float val = x[jBeg + lane_id];
		for (size_t j = 0; j &lt; warp_size; ++j) //能够自动展开
			res += Ac[(j + jBeg) * m + i] * __shfl_sync(0xffffffff, val, j, warp_size);
	}
	{
		const float val = jBegLast + lane_id &lt; n ? x[jBegLast + lane_id] : 0;
		for (size_t j = 0; j &lt; n - jBegLast; ++j) //不能自动展开
			res += Ac[(j + jBegLast) * m + i] * __shfl_sync(0xffffffff, val, j, warp_size);
	}
	if (i &lt; m)
		y[i] = res;
}
int main()
{
	const size_t
		m = 1 &lt;&lt; 14,
		n = 1 &lt;&lt; 14;
	float
		*h_Ar,
		*h_Ac,
		*h_x,
		*d_Ar,
		*d_Ac,
		*d_x,
		*d_y;
	cudaHostAlloc(
		(void **)&amp;h_Ar,
		sizeof(float) * m * n,
		cudaHostAllocWriteCombined);
	cudaHostAlloc(
		(void **)&amp;h_Ac,
		sizeof(float) * m * n,
		cudaHostAllocWriteCombined);
	cudaHostAlloc(
		(void **)&amp;h_x,
		sizeof(float) * n,
		cudaHostAllocWriteCombined);
	for (size_t j = 0; j &lt; n; ++j)
	{
		h_x[j] = log(sqrt(j * j - j + 2));
		for (size_t i = 0; i &lt; m; ++i)
			h_Ac[j * m + i] = h_Ar[i * n + j] = i - 0.1 * j + 1;
	}
	cudaMalloc(
		(float **)&amp;d_Ar,
		sizeof(float) * m * n);
	cudaMalloc(
		(float **)&amp;d_Ac,
		sizeof(float) * m * n);
	cudaMalloc(
		(float **)&amp;d_x,
		sizeof(float) * n);
	cudaMalloc(
		(float **)&amp;d_y,
		sizeof(float) * m);
	cudaMemcpy(
		d_Ar,
		h_Ar,
		sizeof(float) * m * n,
		cudaMemcpyHostToDevice);
	cudaMemcpy(
		d_Ac,
		h_Ac,
		sizeof(float) * m * n,
		cudaMemcpyHostToDevice);
	cudaMemcpy(
		d_x,
		h_x,
		sizeof(float) * n,
		cudaMemcpyHostToDevice);
	cudaMemcpyToSymbol(
		d_cx,
		h_x,
		sizeof(float) * n,
		cudaMemcpyHostToDevice);
	cudaFreeHost(h_Ar);
	cudaFreeHost(h_Ac);
	cudaFreeHost(h_x);
	cublasHandle_t wk_cublas_handle;
	cublasCreate(&amp;wk_cublas_handle);
	float
		alpha = 1,
		beta = 0;
	for (int i = 0; i &lt; 7; ++i)
	{
		cudaEvent_t beg, end;
		cudaEventCreate(&amp;beg);
		cudaEventCreate(&amp;end);
		cudaEventRecord(beg, 0);
		const size_t
			blocks = 1 &lt;&lt; 7,
			grids = (m + blocks - 1) / blocks;
		if (i == 0)
			wkSgemvGlobalMemory&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;(
				d_Ar,
				d_x,
				d_y,
				m,
				n);
		else if (i == 1)
			wkSgemvGlobalMemoryAlign&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;(
				d_Ac,
				d_x,
				d_y,
				m,
				n);
		else if (i == 2)
			wkSgemvConstantMemory&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;(
				d_Ac,
				d_x,
				d_y,
				m,
				n);
		else if (i == 3)
			wkSgemvSharedMemory&lt;blocks&gt;&lt;&lt;&lt;grids, blocks, sizeof(float) * blocks&gt;&gt;&gt;(
				d_Ac,
				d_x,
				d_y,
				m,
				n);
		else if (i == 4)
			wkSgemvWarp&lt;32&gt;&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;(
				d_Ac,
				d_x,
				d_y,
				m,
				n);
		else if (i == 5)
			cublasSgemv(
				wk_cublas_handle,
				CUBLAS_OP_T,
				m,
				n,
				&amp;alpha,
				d_Ar,
				m,
				d_x,
				1,
				&amp;beta,
				d_y,
				1);
		else if (i == 6)
			cublasSgemv(
				wk_cublas_handle,
				CUBLAS_OP_N,
				m,
				n,
				&amp;alpha,
				d_Ac,
				m,
				d_x,
				1,
				&amp;beta,
				d_y,
				1);
		cudaDeviceSynchronize();
		cudaEventRecord(end, 0);
		cudaEventSynchronize(beg);
		cudaEventSynchronize(end);
		float elapsed_time;
		cudaEventElapsedTime(&amp;elapsed_time, beg, end);
		printf("%fms\n", elapsed_time);
	}
	cublasDestroy(wk_cublas_handle);
	cudaFree(d_Ar);
	cudaFree(d_Ac);
	cudaFree(d_x);
	cudaFree(d_y);
}
</code></pre>

</div>
<div class="v">
  <i class="fas fa-spinner fa-pulse"></i>
</div>
<script
  src='https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js'
  defer='defer'
  onload='
    new Valine({
      "el": document.getElementsByClassName("v")[0],
      "appId": "9hABRddSuEkTgqLrt1VSK5B1-gzGzoHsz",
      "appKey": "NJ7RwmgrxsF7KDzlqU7YewlL",
      "placeholder": "在这里评论吧！填写邮箱可以获得 Gravatar 头像和回复通知哦",
      "requiredFields": ["nick","mail"],
      "visitor": true,
      "recordIP": true
    })'
></script>

</div>
  </div>
  
  <label for="sidebar-checkbox" class="sidebar-toggle"></label>
  
</body>

</html>