<!DOCTYPE html>
<html>

<head>
  
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>稀疏矩阵乘法 | wu-kan</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="稀疏矩阵乘法" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="实验简介" />
<meta property="og:description" content="实验简介" />
<link rel="canonical" href="http://localhost:4000/_posts/2020-01-13-%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/" />
<meta property="og:url" content="http://localhost:4000/_posts/2020-01-13-%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/" />
<meta property="og:site_name" content="wu-kan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-13T00:00:00+08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://localhost:4000/_posts/2020-01-13-%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/","headline":"稀疏矩阵乘法","dateModified":"2020-01-13T00:00:00+08:00","datePublished":"2020-01-13T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/_posts/2020-01-13-%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/"},"description":"实验简介","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  
  
  <meta
  name="viewport"
  content="width=device-width, initial-scale=1.0, maximum-scale=1"
/>
<meta
  http-equiv="content-type"
  content="text/html; charset=utf-8"
/>
<link
  rel="alternate"
  href="/feed.xml"
  title="RSS"
  type="application/rss+xml"
/>

  
  <link
  rel="apple-touch-icon-precomposed"
  href="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=320"
/>
<link
  rel="shortcut
  icon"
  href="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=32"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/combine/gh/poole/lanyon@v1.1.0/public/css/poole.min.css,gh/poole/lanyon@v1.1.0/public/css/lanyon.min.css"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/Dreamer-Paul/Pio@2.4/static/pio.min.css"
/>
<script
  async="async"
  src="https://cdn.jsdelivr.net/combine/gh/Dreamer-Paul/Pio@2.4/static/l2d.min.js,gh/Dreamer-Paul/Pio@2.4/static/pio.min.js"
  onload='
      let pio_container = document.createElement("div");
      pio_container.classList.add("pio-container");
      pio_container.classList.add("right");
      pio_container.style.bottom = "-2rem";
      pio_container.style.zIndex = "1";
      document.body.insertAdjacentElement("beforeend", pio_container);
      let pio_action = document.createElement("div");
      pio_action.classList.add("pio-action");
      pio_container.insertAdjacentElement("beforeend", pio_action);
      let pio_canvas = document.createElement("canvas");
      pio_canvas.id = "pio";
      pio_canvas.style.width = "14rem";
      pio_canvas.width = "600";
      pio_canvas.height = "800";
      pio_container.insertAdjacentElement("beforeend", pio_canvas);
      let pio = new Paul_Pio({
        "mode": "fixed",
        "hidden": true,
        "night": "for(let i=7; i<16; ++i) if(document.body.classList.contains(`theme-base-0`+i.toString(16))) { document.body.classList.remove(`theme-base-0`+i.toString(16)); document.body.classList.add(`theme-base-0`+((i-6)%9+7).toString(16)); break; }",
        "content": {
          "link": ["https://jekyll-theme-WuK.wu-kan.cn"],
          "skin": ["要换成我的朋友吗？", "让她放个假吧~"],
          "hidden": true,
          "custom": [{
            "selector": "a",
            "type": "link",
          }, {
            "selector": ".sidebar-toggle",
            "text": "打开侧边栏叭~"
          }, {
            "selector": ".effect-info",
            "text": "哇，你发现了什么！"
          }, {
            "selector": "#sidebar-search-input",
            "text": "想搜索什么呢？很多干货哦！"
          }, {
            "selector": "#toc",
            "text": "这是目录~"
          }, {
            "selector": ".page-title",
            "text": "这是标题~"
          }, {
            "selector": ".v",
            "text": "评论没有审核，要对自己的发言负责哦~"
          }]
        },
        "model": [
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/33/model.2018.bls-winter.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/platelet-2/model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/xiaomai/xiaomai.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/mashiro/seifuku.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/Violet/14.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/Kobayaxi/Kobayaxi.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/mikoto/mikoto.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/uiharu/uiharu.model.json"]
      });'
></script>

  
  <script
  src='https://zz.bdstatic.com/linksubmit/push.js'
  async="async"
></script>

  
  <script
  async="async"
  src="https://www.googletagmanager.com/gtag/js?id=UA-163543967-1"
  onload="
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-163543967-1');"
></script>

  
  <style>
  .wrap {
    transition-property: all;
    transition-duration: .3s;
    transition-timing-function: ease-in-out;
    min-height: 100%;
    display: inline-block;
    background-size: 100% auto;
    background-position: 0% 0%;
    background-repeat: no-repeat;
    background-attachment: fixed;
    background-image: url(https://Mizuno-Ai.wu-kan.cn/pixiv/74559485_p1.webp);
  }
  @media (min-aspect-ratio: 2400/1850) {
    .wrap {
      background-image: url(https://Mizuno-Ai.wu-kan.cn/pixiv/71932901_p0.webp);
    }
  }
  .sidebar-overlay #sidebar-checkbox:checked ~ .wrap {
    width: calc(100% - 14rem);
    background-size: calc(100% - 14rem) auto;
    left: 14rem;
  }
  .layout-reverse.sidebar-overlay #sidebar-checkbox:checked ~ .wrap {
    left: 0;
  }
</style>

  
  <style>
  html,
  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  .sidebar {
    font-family: PingFang SC, Menlo, Monaco, "Courier New", Microsoft JhengHei, monospace;
  }
</style>

  
  <style>
  img {
    display: inline-block;
    margin: 0;
  }
</style>

  
  <style>
  ::-webkit-scrollbar {
    width: 4px;
    height: 4px;
  }
  ::-webkit-scrollbar-thumb {
    background-image: linear-gradient(45deg, Cyan 0%, Magenta 50%, Yellow 100%);
  }
</style>

  
  <style>
  ::selection {
    color: White;
    background: Black;
  }
</style>

  
</head>

<body
  class="theme-base-07 layout-reverse sidebar-overlay">
  
  
  
  <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
  <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"
     />
  <!-- Toggleable sidebar -->
  <div class="sidebar" id="sidebar">
    
    <div class="sidebar-item">
      <div class="effect effect-right_to_left">
        <img class="effect-img" src="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=320" alt="img" />
        <div class="effect-info">
          SYSU超算17级在读<br/>
永远喜欢水野爱<br/>
田宫例四驱车<br/>
ASC<br/>
<a href="mailto:i@wu-kan.cn">
  <i class="fas fa-envelope"></i>
</a>
<a href="https://github.com/wu-kan">
  <i class="fab fa-github"></i>
</a>
<a href="https://codeforces.com/profile/WuK">
  <i class="fas fa-chart-bar"></i>
</a>
<a href="https://vjudge.net/user/WuK">
  <i class="fas fa-smile"></i>
</a>
<a href="https://www.zhihu.com/people/wu.kan/activities">
  <i class="fab fa-zhihu"></i>
</a>
<iframe
  src="https://music.163.com/outchain/player?type=0&id=155059595&auto=0&height=32"
  width=100%
  height=52
  frameborder="no"
  border="0"
  marginwidth="0"
  marginheight="0"
></iframe>

        </div>
      </div>
    </div>
    
    <nav class="sidebar-nav">
      
      <a class="sidebar-nav-item" href="/">
        <i class="fas fa-home fa-fw"></i> 首页
      </a>
      
      <a class="sidebar-nav-item" href="/comments/">
        <i class="fas fa-comments fa-fw"></i> 留言
      </a>
      
      <a class="sidebar-nav-item" href="/tags/">
        <i class="fas fa-tags fa-fw"></i> 标签
      </a>
      
      <a class="sidebar-nav-item" href="/archive/">
        <i class="fas fa-archive fa-fw"></i> 归档
      </a>
      
      <a class="sidebar-nav-item" href="/merger/">
        <i class="fas fa-coffee fa-fw"></i> 打赏
      </a>
      
    </nav>
    <div class="sidebar-item">
      
      <div>
        <style>
  #sidebar-search-input {
    background: none;
    border: none;
    color: White;
    width: 100%;
  }
  #sidebar-search-results-container {
    overflow: auto auto;
    max-height: 50vh;
  }
</style>
<input
  id="sidebar-search-input"
  placeholder="搜索博文"
/>
<ol
  id="sidebar-search-results-container"
></ol>
<script
  src='https://cdn.jsdelivr.net/npm/simple-jekyll-search/dest/simple-jekyll-search.min.js'
  async='async'
  onload='
    SimpleJekyllSearch({
      json: "/assets/simple-jekyll-search/search.json",
      searchInput: document.getElementById("sidebar-search-input"),
      resultsContainer: document.getElementById("sidebar-search-results-container"),
      searchResultTemplate: `<li><a href="{url}">{title}</a></li>`,
      limit: 999,
      fuzzy: true
    })'
></script>

      </div>
      
      
      <style>
  .sidebar-checkbox {
    display: none;
  }
  .sidebar-toggle {
    position: fixed;
  }
</style>

      
      <style>
  .effect {
    margin: 1rem;
    perspective: 900px;
  }
  .effect-info {
    text-align: center;
    backface-visibility: hidden;
    position: absolute;
    top: 0;
    transform-style: preserve-3d;
  }
  .effect-img {
    z-index: 11;
    width: 100%;
    height: 100%;
    position: relative;
    transition: all 0.5s ease-in-out;
  }
  .effect-img:before {
    position: absolute;
    display: block;
  }
  .effect-right_to_left .effect-img {
    transform-origin: 0% 50%;
  }
  .effect-right_to_left:hover .effect-img {
    transform: rotate3d(0, 1, 0, -180deg);
  }
</style>

      
      <style>
  #toc {
    overflow: auto auto;
    max-height:50vh;
  }
</style>
<aside id="toc">
  目录
</aside>
<script
  defer='defer'
  src='https://cdn.jsdelivr.net/npm/html-contents/html-contents.min.js'
  onload="htmlContents('#toc', {listType: 'o', filter: function(arr) {return !arr.matches('.masthead-title')}})"
></script>

      
      <div>
  <i class="fas fa-cog fa-spin fa-fw"></i>
  <span id="run_time_day">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>天
  <span id="run_time_hour">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>时
  <span id="run_time_minute">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>分
  <span id="run_time_second">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>秒
  <script>
    setInterval(function (BirthDay) {
      function setzero(i) {
        if (i < 10) return "0" + i;
        return i;
      }
      BirthDay = new Date(BirthDay);
      today = new Date();
      timeold = (today.getTime() - BirthDay.getTime());
      sectimeold = timeold / 1000;
      secondsold = Math.floor(sectimeold);
      msPerDay = 24 * 60 * 60 * 1000;
      e_daysold = timeold / msPerDay;
      daysold = Math.floor(e_daysold);
      e_hrsold = (e_daysold - daysold) * 24;
      hrsold = Math.floor(e_hrsold);
      e_minsold = (e_hrsold - hrsold) * 60;
      minsold = Math.floor((e_hrsold - hrsold) * 60);
      seconds = Math.floor((e_minsold - minsold) * 60);
      document.getElementById("run_time_day").innerHTML = daysold;
      document.getElementById("run_time_hour").innerHTML = setzero(hrsold);
      document.getElementById("run_time_minute").innerHTML = setzero(minsold);
      document.getElementById("run_time_second").innerHTML = setzero(seconds);
    }, 1000, "10/04/2017 11:03:56") // 这是我第一篇CSDN博客的时间
  </script>
</div>

      
      <div>
  <div>
    <i class="fas fa-eye fa-fw"></i>
    <span id="busuanzi_value_page_pv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>次
  </div>
  <div>
    <i class="fas fa-paw fa-fw"></i>
    <span id="busuanzi_value_site_pv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>枚
  </div>
  <div>
    <i class="fas fa-user-friends fa-fw"></i>
    <span id="busuanzi_value_site_uv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>人
  </div>
  <script
    src='https://cdn.jsdelivr.net/npm/busuanzi'
    async='async'
  ></script>
</div>

      
      <div>
  <i class="fas fa-copyright fa-fw"></i>
  2017-2020 WuK
</div>

      
      <div>
  <i class="fas fa-thumbs-up fa-fw"></i>
  <a href="https://jekyll-theme-WuK.wu-kan.cn">
    jekyll-theme-WuK
  </a>
</div>

      
      <div>
  <i class="fas fa-info-circle fa-fw"></i>
  <a href="http://beian.miit.gov.cn">
    粤ICP备20024947号
  </a>
</div>

      
      
    </div>
  </div>
  <!-- Wrap is the content to shift when toggling the sidebar. We wrap the content to avoid any CSS collisions with our real content. -->
  
  <div class="wrap">
    
<style>
  pre {
    max-height: 50vh;
    overflow: auto;
  }
</style>


<style>
  @media (min-width: 56em) {
    .container {
      max-width: 66.6%;
    }
  }
</style>


<style>
  .masthead,
  .container.content {
    padding-top: 1rem;
    padding-bottom: 1rem;
    box-shadow: 0 0 .75rem rgba(0, 0, 0, 0.1);
    background-color: rgba(255, 255, 255, 0.95);
    animation-duration: 2s;
    animation-name: fadeIn;
  }
  @keyframes fadeIn {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }
</style>


<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/combine/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.css,npm/prismjs/plugins/toolbar/prism-toolbar.min.css,gh/PrismJS/prism-themes@1955cfef6953b3a59e66016e8a1e016b45d6cc79/themes/prism-nord.min.css"
/>
<script
  src="https://cdn.jsdelivr.net/combine/npm/prismjs/components/prism-core.min.js,npm/prismjs/plugins/autoloader/prism-autoloader.min.js,npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js,npm/prismjs/plugins/toolbar/prism-toolbar.min.js"
  defer="defer"
  onload='
    Prism.plugins.autoloader.languages_path = "https:\/\/cdn.jsdelivr.net/npm/prismjs/components/";
    for(let x=document.getElementsByTagName("pre"), i=0;i<x.length;i++)
    {
      x[i].classList.add("line-numbers");
    }
    Prism.plugins.toolbar.registerButton("select-code", function (env) {
      let button = document.createElement("button");
      button.innerHTML = "select this " + env.language;
      button.addEventListener("click", function () {
        if (document.body.createTextRange) {
          let range = document.body.createTextRange();
          range.moveToElementText(env.element);
          range.select();
        } else if (window.getSelection) {
          let selection = window.getSelection();
          let range = document.createRange();
          range.selectNodeContents(env.element);
          selection.removeAllRanges();
            selection.addRange(range);
        }
      });
      return button;
    })'
></script>


<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"
/>
<script
  src="https://cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/mathtex-script-type.min.js,npm/katex/dist/contrib/auto-render.min.js"
  defer="defer"
  onload='renderMathInElement(document.body, { delimiters: [{ left: "$", right: "$", display: false }] })'
></script>


<style>
  pre.language-mermaid,
  code.language-mermaid {
    display: none;
  }
</style>
<script
  src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"
  defer="defer"
  onload='
  for(let x=document.getElementsByClassName("language-mermaid"), i=0;i<x.length;i++)
    if(x[i].nodeName=="CODE")
    {
      let m = document.createElement("div");
      m.classList.add("mermaid");
      m.textContent = x[i].textContent;
      x[i].parentNode.insertAdjacentElement("beforebegin", m);
    }'
></script>



<div class="masthead">
  <h3 class="container masthead-title">
    
    稀疏矩阵乘法
    <a href="http://localhost:4000/" title="Home">
      <small>
        wu-kan
      </small>
    </a>
    
  </h3>
</div>

<div class="container content">
  <div class="post">
  <span class="post-date">
    
    <i class="fas fa-calendar-day fa-fw"></i>
    13 Jan 2020
    
    
    <i class="fas fa-file-word fa-fw"></i>
    22707字
    
    
    <i class="fas fa-clock fa-fw"></i>
    76分
    
    
    
    <i class="fas fa-tag fa-fw"></i>
    高性能计算
    
    <br/>
<i class="fas fa-coffee fa-fw"></i>
<a href="/merger/">如果这篇博客帮助到你，可以请我喝一杯咖啡~</a>
<br/>
<i class="fab fa-creative-commons-by fa-fw"></i>
<a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">CC BY 4.0</a>（除特别声明或转载文章外）

    
  </span>
  <h2 id="实验简介">实验简介</h2>

<p>分别使用 MPI 和 CUDA 实现稀疏矩阵乘法，输入输出矩阵都用压缩行格式存储；并与串行程序比较。</p>

<h2 id="实验环境">实验环境</h2>

<p>实验在老师提供的计算集群的一个节点上进行。单节点的显卡配置如下：</p>

<pre><code class="language-bash">$ nvdia-smi
Mon Dec  2 08:38:49 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0    24W / 250W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre>

<h2 id="实验原理">实验原理</h2>

<p>稀疏矩阵乘法在工程上有着重要的应用，然而稀疏矩阵本身的存储方式决定了它不容易像稠密矩阵一样划分到多线程并行计算。下面介绍我完成本次实验的一些思考和用到的一些记号。</p>

<h3 id="稀疏矩阵">稀疏矩阵</h3>

<p>本例中，用到的稀疏矩阵在内存中的存储形式有如下三种：</p>

<ul>
  <li>坐标格式（Coordinate Format, COO）
    <ul>
      <li>用三元组<code>(RowInd, ColInd, Val)</code>定义矩阵中的元素。</li>
      <li>分别表示元素的行坐标、列坐标、取值。</li>
    </ul>
  </li>
  <li>行压缩格式（Compressed Sparse Row Format, CSR）
    <ul>
      <li>用三元组<code>(RowPtr, ColInd, Val)</code>定义矩阵中的元素。</li>
      <li>将矩阵内的元素按照先行坐标后列坐标的顺序排序。</li>
      <li>此时同一行的元素在内存上的排列是相邻的。</li>
      <li>左闭合区间<code>[ RowPtr[i] , RowPtr[i + 1] )</code>内可以唯一确定同一行的所有元素。</li>
      <li>同一行的元素之间使用列坐标<code>ColInd</code>区分，元素值为<code>Val</code>。</li>
    </ul>
  </li>
  <li>列压缩格式（Compressed Sparse Column Format, CSC）
    <ul>
      <li>用三元组<code>(ColPtr, RowInd, Val)</code>定义矩阵中的元素。</li>
      <li>类似于行压缩格式转置后的结果。</li>
    </ul>
  </li>
</ul>

<p>由于稀疏矩阵的操作比较复杂，此处我将它封装成了一个简单的稀疏矩阵处理库<code>&lt;WuKSPARSE.h&gt;</code>。下面是一个稀疏矩阵的存储方法，同时支持上述三种存储格式。</p>

<pre><code class="language-c">typedef struct Scoo
{
	int
		m,   //行
		n,   //列
		nnz; //非零元素数量
	IntVector
		RowPtr, //大小m+1
		ColPtr, //大小n+1
		RowInd, //大小nnz，行坐标
		ColInd; //大小nnz，列坐标
	FloatVector
		Val; //大小为nnz
} Scoo;
</code></pre>

<p>命名方式类似于<a href="https://docs.nvidia.com/cuda/cusparse/">Nvidia<code>&lt;cusparse.h&gt;</code>库</a>。由于操作的过程中可能会丢失行优先的性质但是坐标对的性质始终得到保留，因此命名<code>Scoo</code>表明这是一个单精度（<code>S</code>）的坐标格式（<code>coo</code>）稀疏矩阵。后续实验的时候会确保乘法之前是使用行优先的存储。</p>

<p>由于稀疏矩阵中存在着大量内存管理的过程，这里我封装了<code>IntVector</code>和<code>FloatVector</code>，功能类似于 C++ STL 中的<code>vector&lt;int&gt;</code>和<code>vector&lt;float&gt;</code>。没有直接使用 C++是因为想保持语法的纯粹性，而不想让 C++中很多语法糖影响自己对代码结构的判断。这样的好处是后续实验中对内存的分配管理都是通过这两个类型进行，更加稳定。</p>

<p>我实现了如下的接口供调用。</p>

<pre><code class="language-c">void ScooFree(Scoo *a); //释放矩阵申请的内存空间
void ScooMalloc(Scoo *a); //根据矩阵的m和n和nnz为矩阵申请内存空间
void ScooPushBack(Scoo *a, int r, int c, float v); //向矩阵插入一个新的元素，可能会破坏原先的索引
void ScooRead(Scoo *a, FILE *f); //读取MatrixMarket格式的矩阵
void ScooWrite(const Scoo *a, FILE *f); //将矩阵转化为MatrixMarket格式输出
void ScsrInit(Scoo *a); //假设矩阵三元组的存储已经符合列压缩的要求，并为其生成行索引
void ScooToScsr(const Scoo *a, Scoo *b); //将矩阵元素排序并转换成行压缩格式，并为其生成行索引
void ScscInit(Scoo *a);  //假设矩阵三元组的存储已经符合列压缩的要求，并为其生成列索引
void ScooToScsc(const Scoo *a, Scoo *b); //将矩阵元素排序并转换成列压缩格式，并为其生成列索引
</code></pre>

<p>假设要求的矩阵乘法$A\times B=C$，这里老师给的数据生成器使用默认参数会生成如下两个 MatrixMarket 格式的矩阵。注意到这里生成的矩阵中有很多不合理的下标（如<code>-1</code>），我封装的函数会将它们从输入中筛去，以保证程序正确运行。</p>

<p>第一个矩阵$A$对应的<code>matrix12.mat</code>的前十行：</p>

<pre><code class="language-matlab">%%MatrixMarket matrix coordinate real general
8191 8191 784379
0 -1 1.0
0 0 1.0
1 -1 1.0
1 0 1.0
2 -1 1.0
2 0 1.0
0 1 1.0
0 2 1.0
...
</code></pre>

<p>第二个矩阵$B$对应的<code>matrix.mat</code>的前十行：</p>

<pre><code class="language-matlab">%%MatrixMarket matrix coordinate real general
8191 8191 46796
0 -1 1.0
0 0 1.0
1 -1 1.0
1 0 1.0
2 -1 1.0
2 0 1.0
0 1 1.0
0 2 1.0
...
</code></pre>

<h3 id="动态向量">动态向量</h3>

<p>这里给出<code>&lt;WuKfloatVector.h&gt;</code>中<code>FloatVector</code>的相关定义和接口。<code>&lt;WuKintVector.h&gt;</code>中<code>IntVector</code>的定义和接口类似。</p>

<pre><code class="language-c">typedef struct FloatVector
{
    int size, cap; //大小和实际容量
    float *data; //指向元素的指针
} FloatVector;
void FloatVectorFree(FloatVector *v); //释放v申请的内存资源
void FloatVectorInit(FloatVector *v, int size); //初始化一个大小为size的向量
void FloatVectorPushBack(FloatVector *v, float val); //向向量末尾插入新的元素，如果容量不够会重新分配两倍的空间，从而保证动态插入的均摊时间复杂度是常数
</code></pre>

<h3 id="串行稀疏矩阵乘法">串行稀疏矩阵乘法</h3>

<p>矩阵乘法的本质是对矩阵$A$的所有行向量和矩阵的$B$的所有列向量做点积操作，因此要获取两个矩阵的行向量和列向量。</p>

<p>由于初始矩阵是按照行优先的顺序存储的，因此可以直接获得矩阵的行向量。要获得矩阵的列向量，需要将矩阵内的元素重新排序转换成列优先的顺序，所需要的时间复杂度为$O(nnz\log nnz)$。当然，也可以通过定位行向量的索引，用$m$路归并排序实现更优的线性复杂度。</p>

<p>随后就可以对行优先矩阵和列优先矩阵做稀疏向量点积运算。注意到这里算点积的顺序天然就是行优先的，因此生成的矩阵$C$也是行优先矩阵，无需再做转换。时间复杂度为$O(m\times n\times l)$，三个变量分别是矩阵的宽、高、稀疏向量点积的平均时间。容易看出，当稀疏向量点积的平均时间小于稠密向量点积的时间时，稀疏矩阵乘法是要远远优于稠密矩阵乘法的。</p>

<p>此外还有一个 trick，在第二层循环开始之前先判断了 A 这一行是否为空行，可以根据矩阵 A 的稀疏情况大大减少循环次数，实现性能上的调优。</p>

<pre><code class="language-c">void ScsrMulScsc(const Scoo *a, const Scoo *b, Scoo *c)
{
	c-&gt;m = a-&gt;m;
	c-&gt;n = b-&gt;n;
	c-&gt;nnz = 0;
	ScooMalloc(c);
	for (int i = 0; i &lt; c-&gt;m; ++i)
		if (a-&gt;RowPtr.data[i] &lt; a-&gt;RowPtr.data[i + 1])
			for (int j = 0; j &lt; c-&gt;n; ++j)
			{
				float res = 0;
				for (int
						 kb = b-&gt;ColPtr.data[j],
						 ka = a-&gt;RowPtr.data[i];
					 kb &lt; b-&gt;ColPtr.data[j + 1] &amp;&amp;
					 ka &lt; a-&gt;RowPtr.data[i + 1];
					 ++kb)
					if (b-&gt;Val.data[kb])
					{
						while (a-&gt;ColInd.data[ka] &lt; b-&gt;RowInd.data[kb])
							++ka;
						while (a-&gt;ColInd.data[ka] == b-&gt;RowInd.data[kb])
							res += a-&gt;Val.data[ka] * b-&gt;Val.data[kb], ++ka;
					}
				if (res)
					ScooPushBack(c, i, j, res);
			}
	ScsrInit(c);
}
void ScsrMulScsr(const Scoo *a_csr, const Scoo *b_csr, Scoo *c_csr)
{
	Scoo B_csc;
	ScooToScsc(b_csr, &amp;B_csc);
	ScsrMulScsc(a_csr, &amp;B_csc, c_csr);
	ScooFree(&amp;B_csc);
}
</code></pre>

<p>串行稀疏矩阵乘法的用时为<code>6.199s</code>，其输出结果<code>sparseScsrmm_out.txt</code>的前十行如下。</p>

<pre><code class="language-matlab">%MatrixMarket matrix coordinate real general
8191 8191 4185601
0 0 511.000000
0 1 511.000000
0 2 511.000000
0 3 448.000000
0 4 511.000000
0 5 511.000000
0 6 511.000000
0 7 282.000000
</code></pre>

<h3 id="mpi-稀疏矩阵乘法">MPI 稀疏矩阵乘法</h3>

<p>重新分析一下串行算法的过程，可以分成如下两各阶段：</p>

<ol>
  <li>将第二个矩阵转换成列优先的格式</li>
  <li>对第一个矩阵的行向量和第二个矩阵的列向量分别做稀疏向量点积</li>
</ol>

<p>第一步的本质就是对三元组按照列优先的顺序对矩阵进行重排序，因此可以使用常见的并行排序方法对其进行优化，优化后的期望时间复杂度是$O(\frac{nnz}{p}\log\frac{nnz}{p})$，其中$p$是并行的核数。或者也可以在$m$路归并的基础上将其优化。</p>

<p>我对第二步的优化方法是，将第一个矩阵$A$按顺序拆分到各个进程上分别执行子矩阵的稀疏矩阵乘法，最后使用<code>MPI_Gatherv</code>汇集成完整的答案$C$。</p>

<p>由于使用 MPI 写出来的代码有很多 API 调用过于繁琐，这里先描述一下 MPI 算法的流程，详细细节可以看后面的代码<code>sparseScsrmm_mpi.c</code>。</p>

<ol>
  <li>使用并行排序方法将矩阵$B$转化成列优先存储格式，并广播到每个进程</li>
  <li>使用<code>MPI_Scatter</code>将行优先矩阵$A$按照顺序均分到各个进程。由于$A$是行优先的，拆分后各个进程获得的$A_{local}$也是行优先的。</li>
  <li>各个进程做串行稀疏矩阵乘法$A_{local}\times B=C_{local}$</li>
  <li>各个进程将$C_{local}$汇总到根进程得到答案$C$。由于$C_{local}$的行与$A_{local}$的行是高度对应的，因此$C_{local}$也是行优先矩阵，汇总得到的$C$也是行优先矩阵，无需特殊处理。</li>
</ol>

<p>MPI 稀疏矩阵乘法的用时为<code>23.416s</code>，相对于串行算法增加了。这是因为算法在最开始的时候有一个将矩阵$A$散射到各个进程，而结束的时候将矩阵$C$收集到主进程输出，通信开销非常大。</p>

<p>但是实际生产情况中，通常要求各个进程持有待处理矩阵的一部分即可，便于进行多轮矩阵乘法（类似 Cannon 并行稠密矩阵乘法的优点，多次执行<code>A = A * B</code>时不用汇总到主进程）。在这种情况下，MPI 并行化的稠密矩阵乘法还是很有优势的；并且，矩阵$B$转成列优先也只用转一次（但是多轮矩阵乘法之后稀疏矩阵逐渐会变得稠密…）。</p>

<p>输出结果<code>sparseScsrmm_mpi_out.txt</code>的前十行如下。</p>

<pre><code class="language-matlab">%MatrixMarket matrix coordinate real general
8191 8191 4187926
0 0 511.000000
0 1 511.000000
0 2 511.000000
0 3 448.000000
0 4 511.000000
0 5 511.000000
0 6 511.000000
0 7 282.000000
...
</code></pre>

<p>注意到这里输出的答案中非零元素的数量<code>4187926</code>大于之前的<code>4185601</code>，是因为我按照均分的元素拆分方式导致某些行向量从中间“断开”了，导致结果出现同一个坐标上的多个值，在稀疏矩阵的坐标存储方式是允许的。如果不希望同一个坐标多次出现可以用线性的去重<code>unique</code>算法，这里就没有做了。</p>

<h3 id="cuda-稀疏矩阵乘法">CUDA 稀疏矩阵乘法</h3>

<p>CUDA 上的稀疏矩阵乘法不能完全按照 MPI 版本中的并行算法来运行，这是由显卡的如下两个特性决定的：</p>

<ul>
  <li>没有全局的同步函数（当然可以通过多次启动核函数解决，但是效率不高）</li>
  <li>核函数内部不能动态对一个向量进行扩张</li>
</ul>

<p>关于后一点，我尝试使用了英伟达提供的动态向量类型<code>thrust::device_vector</code>，结果发现其<code>push_back</code>操作不能由核函数调用（那我要你有何用）。因此需要为 CUDA 版本设计新的并行算法。</p>

<p>我使用二维划分的线程块，每个线程对应答案矩阵的一个元素，或者一次稀疏向量点积运算。这种算法没有用于之前的两个算法，是因为它需要预先分配$m\times n$的空间用于存储每个位置的值，使得之前的算法退化成稠密矩阵算法。但是，显卡的另一个特性就是显存大，线程极多，新开线程开销极小。因此，可以新开一个矩阵来收集每个线程计算的结果。当然，这样计算得到的结果是稠密矩阵，需要使用线性算法扫描整个矩阵，重新转成符合要求的行优先矩阵。</p>

<p>下面是 CUDA 稀疏矩阵乘法的核函数，出人意料地简洁。</p>

<pre><code class="language-c">void __global__ cuScsrMulScs(
	const int *a_csr_RowPtr,
	const int *a_csr_CowInd,
	const float *a_csr_Val,
	const int *b_csc_ColPtr,
	const int *b_csc_RowInd,
	const float *b_csc_Val,
	float *c,
	int m,
	int n)
{
	int
		i = blockIdx.x * blockDim.x + threadIdx.x,
		j = blockIdx.y * blockDim.y + threadIdx.y;
	float res = 0;
	for (int
			 kb = b_csc_ColPtr[j],
			 ka = a_csr_RowPtr[i];
		 kb &lt; b_csc_ColPtr[j + 1] &amp;&amp;
		 ka &lt; a_csr_RowPtr[i + 1];
		 ++kb)
	{
		while (a_csr_CowInd[ka] &lt; b_csc_RowInd[kb])
			++ka;
		while (a_csr_CowInd[ka] == b_csc_RowInd[kb])
			res += a_csr_Val[ka] * b_csc_Val[kb], ++ka;
	}
	c[i * n + j] = res;
}
</code></pre>

<p>分析一下核函数的运行情况：</p>

<ul>
  <li>沿 x 方向对<code>b_csc_ColPtr</code>访存连续</li>
  <li>沿 y 方向对<code>a_csr_RowPtr</code>访存连续</li>
  <li>对<code>c[i * n + j]</code>的访存连续</li>
  <li>对<code>a_csr_Val[ka]</code>和<code>b_csc_Val[kb]</code>访存不连续</li>
  <li>多个<code>while</code>存在分支</li>
</ul>

<p>后两者应该是这个算法的瓶颈，也是稀疏矩阵乘法难以被并行化的主要原因。</p>

<p>在主机上用下面的代码调用核函数。</p>

<pre><code class="language-c">dim3
	block(16, 16),
	grid(a_csr-&gt;m / block.x, B_csc.n / block.y);

cuScsrMulScs&lt;&lt;&lt;grid, block&gt;&gt;&gt;(
	a_RowPtr,
	a_ColInd,
	a_Val,
	b_ColPtr,
	b_RowInd,
	b_Val,
	d_c,
	a_csr-&gt;m,
	B_csc.n);
</code></pre>

<p>CUDA 稀疏矩阵乘法的用时为<code>3.942s</code>，相比于串行稀疏矩阵乘法提速了 57%。其输出结果<code>sparseScsrmm_mpi_out.txt</code>的前十行如下。</p>

<pre><code class="language-matlab">%MatrixMarket matrix coordinate real general
8191 8191 4177936
0 0 511.000000
0 1 511.000000
0 2 511.000000
0 3 448.000000
0 4 511.000000
0 5 511.000000
0 6 511.000000
0 7 282.000000
...
</code></pre>

<p>注意到这里输出的答案中非零元素的数量<code>4177936</code>小于之前的<code>4185601</code>，是因为原来的输入中含有多个元素的位置相同，而这个 CUDA 版本的并行算法将其去重了。</p>

<h2 id="源代码">源代码</h2>

<h3 id="调度脚本sparsescsrmmpbs">调度脚本<code>sparseScsrmm.pbs</code></h3>

<p>这里由于临近期末，集群资源比较紧张，所有的调度都只占用集群上的一个节点进行。MPI 使用一台主机上的 32 个核进行并行；CUDA 使用节点上的单张 v100 显卡。为方便起见，我将所有的测试代码写进了一个测试脚本<code>sparseScsrmm.pbs</code>中，这样直接对这个脚本进行调度运行即可自动运行完整实验并进行计时。</p>

<pre><code class="language-bash">#PBS -N sparseScsrmm
#PBS -l nodes=1:ppn=32:gpus=1
#PBS -j oe
#PBS -q gpu
source /public/software/profile.d/mpi_openmpi-intel-2.1.2.sh
source /public/software/profile.d/cuda10.0.sh
cd $PBS_O_WORKDIR

gcc sparseScsrmm.c -o sparseScsrmm -std=c99
time ./sparseScsrmm matrix12.mat matrix.mat &gt; sparseScsrmm_out.txt

mpicc sparseScsrmm_mpi.c -o sparseScsrmm_mpi -std=c99
time mpiexec -machinefile $PBS_NODEFILE ./sparseScsrmm_mpi matrix12.mat matrix.mat &gt; sparseScsrmm_mpi_out.txt

nvcc sparseScsrmm_cuda.cu -o sparseScsrmm_cuda
time ./sparseScsrmm_cuda matrix12.mat matrix.mat &gt; sparseScsrmm_cuda_out.txt
</code></pre>

<h3 id="运行结果sparsescsrmmo17997">运行结果<code>sparseScsrmm.o17997</code></h3>

<p>自上而下分别是串行算法的时间（<code>6.199s</code>），MPI 算法的时间（<code>23.416s</code>），CUDA 算法的时间（<code>3.942s</code>）。可以看到，这里实现的两个并行算法都在不过分增加并行开销的情况下增加了串行算法的可扩展性。其中 CUDA 算法在原来的算法上得到了 57%的提速，效果还是非常不错的。</p>

<pre><code class="language-bash">
real	0m6.199s
user	0m5.969s
sys	0m0.195s

real	0m23.416s
user	0m39.292s
sys	0m56.808s

real	0m3.942s
user	0m2.988s
sys	0m0.848s
</code></pre>

<h3 id="串行算法sparsescsrmmc">串行算法<code>sparseScsrmm.c</code></h3>

<p>终端执行下述指令，可以计时执行并将结果写入<code>sparseScsrmm_out.txt</code>。</p>

<pre><code class="language-bash">gcc sparseScsrmm.c -o sparseScsrmm -std=c99
time ./sparseScsrmm matrix12.mat matrix.mat &gt; sparseScsrmm_out.txt
</code></pre>

<pre><code class="language-c">#include "WuKSPARSE.h"
void ScsrMulScsc(const Scoo *a, const Scoo *b, Scoo *c)
{
	c-&gt;m = a-&gt;m;
	c-&gt;n = b-&gt;n;
	c-&gt;nnz = 0;
	ScooMalloc(c);
	for (int i = 0; i &lt; c-&gt;m; ++i)
		if (a-&gt;RowPtr.data[i] &lt; a-&gt;RowPtr.data[i + 1])
			for (int j = 0; j &lt; c-&gt;n; ++j)
			{
				float res = 0;
				for (int
						 kb = b-&gt;ColPtr.data[j],
						 ka = a-&gt;RowPtr.data[i];
					 kb &lt; b-&gt;ColPtr.data[j + 1] &amp;&amp;
					 ka &lt; a-&gt;RowPtr.data[i + 1];
					 ++kb)
					if (b-&gt;Val.data[kb])
					{
						while (a-&gt;ColInd.data[ka] &lt; b-&gt;RowInd.data[kb])
							++ka;
						while (a-&gt;ColInd.data[ka] == b-&gt;RowInd.data[kb])
							res += a-&gt;Val.data[ka] * b-&gt;Val.data[kb], ++ka;
					}
				if (res)
					ScooPushBack(c, i, j, res);
			}
	ScsrInit(c);
}
void ScsrMulScsr(const Scoo *a_csr, const Scoo *b_csr, Scoo *c_csr)
{
	Scoo B_csc;
	ScooToScsc(b_csr, &amp;B_csc);
	ScsrMulScsc(a_csr, &amp;B_csc, c_csr);
	ScooFree(&amp;B_csc);
}
int main(int argc, char **argv)
{
	Scoo a_coo, b_coo, a_csr, b_csr, c_csr;

	ScooRead(&amp;a_coo, fopen(argv[1], "r"));
	ScooRead(&amp;b_coo, fopen(argv[2], "r"));

	ScooToScsr(&amp;a_coo, &amp;a_csr);
	ScooToScsr(&amp;b_coo, &amp;b_csr);

	ScooFree(&amp;a_coo);
	ScooFree(&amp;b_coo);

	ScsrMulScsr(&amp;a_csr, &amp;b_csr, &amp;c_csr);

	ScooWrite(&amp;c_csr, stdout);

	ScooFree(&amp;a_csr);
	ScooFree(&amp;b_csr);
	ScooFree(&amp;c_csr);
}
</code></pre>

<h3 id="mpi-算法sparsescsrmm_mpic">MPI 算法<code>sparseScsrmm_mpi.c</code></h3>

<p>终端执行下述指令，可以计时执行并将结果写入<code>sparseScsrmm_mpi_out.txt</code>。</p>

<pre><code class="language-bash">mpicc sparseScsrmm_mpi.c -o sparseScsrmm_mpi -std=c99
time mpiexec -machinefile $PBS_NODEFILE ./sparseScsrmm_mpi matrix12.mat matrix.mat &gt; sparseScsrmm_mpi_out.txt
</code></pre>

<pre><code class="language-c">#include &lt;mpi.h&gt;
#include "WuKSPARSE.h"
void ScsrMulScsc(const Scoo *a, const Scoo *b, Scoo *c)
{
	c-&gt;m = a-&gt;m;
	c-&gt;n = b-&gt;n;
	c-&gt;nnz = 0;
	ScooMalloc(c);
	for (int i = 0; i &lt; c-&gt;m; ++i)
		if (a-&gt;RowPtr.data[i] &lt; a-&gt;RowPtr.data[i + 1])
			for (int j = 0; j &lt; c-&gt;n; ++j)
			{
				float res = 0;
				for (int
						 kb = b-&gt;ColPtr.data[j],
						 ka = a-&gt;RowPtr.data[i];
					 kb &lt; b-&gt;ColPtr.data[j + 1] &amp;&amp;
					 ka &lt; a-&gt;RowPtr.data[i + 1];
					 ++kb)
					if (b-&gt;Val.data[kb])
					{
						while (a-&gt;ColInd.data[ka] &lt; b-&gt;RowInd.data[kb])
							++ka;
						while (a-&gt;ColInd.data[ka] == b-&gt;RowInd.data[kb])
							res += a-&gt;Val.data[ka] * b-&gt;Val.data[kb], ++ka;
					}
				if (res)
					ScooPushBack(c, i, j, res);
			}
	ScsrInit(c);
}
void ScsrMulScsr(const Scoo *a_csr, const Scoo *b_csr, Scoo *c_csr)
{
	Scoo B_csc;
	ScooToScsc(b_csr, &amp;B_csc);
	ScsrMulScsc(a_csr, &amp;B_csc, c_csr);
	ScooFree(&amp;B_csc);
}
int main(int argc, char **argv)
{
	int comSize, comRank;
	MPI_Init(&amp;argc, &amp;argv);
	MPI_Comm_size(MPI_COMM_WORLD, &amp;comSize);
	MPI_Comm_rank(MPI_COMM_WORLD, &amp;comRank);
	Scoo a_coo, b_coo, a_csr, a_csr_local, b_csr, c_csr, c_csr_local;

	if (!comRank)
	{
		ScooRead(&amp;a_coo, fopen(argv[1], "r"));
		ScooRead(&amp;b_coo, fopen(argv[2], "r"));
		ScooToScsr(&amp;a_coo, &amp;a_csr);
		ScooToScsr(&amp;b_coo, &amp;b_csr);
		ScooFree(&amp;a_coo);
		ScooFree(&amp;b_coo);

		for (; a_csr.nnz % comSize; ++a_csr.RowPtr.data[a_csr.m])
			ScooPushBack(&amp;a_csr, a_csr.m - 1, a_csr.n - 1, 0);
		a_csr_local.m = a_csr.m;
		a_csr_local.n = a_csr.n;
		a_csr_local.nnz = a_csr.nnz / comSize;
	}

	MPI_Bcast(
		&amp;a_csr_local.m,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Bcast(
		&amp;a_csr_local.n,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Bcast(
		&amp;a_csr_local.nnz,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	ScooMalloc(&amp;a_csr_local);

	MPI_Scatter(
		a_csr.RowInd.data,
		a_csr_local.nnz,
		MPI_INT,
		a_csr_local.RowInd.data,
		a_csr_local.nnz,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Scatter(
		a_csr.ColInd.data,
		a_csr_local.nnz,
		MPI_INT,
		a_csr_local.ColInd.data,
		a_csr_local.nnz,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Scatter(
		a_csr.Val.data,
		a_csr_local.nnz,
		MPI_FLOAT,
		a_csr_local.Val.data,
		a_csr_local.nnz,
		MPI_FLOAT,
		0,
		MPI_COMM_WORLD);
	ScsrInit(&amp;a_csr_local);

	MPI_Bcast(
		&amp;b_csr.m,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Bcast(
		&amp;b_csr.n,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Bcast(
		&amp;b_csr.nnz,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);
	if (comRank)
		ScooMalloc(&amp;b_csr);

	MPI_Bcast(
		b_csr.RowInd.data,
		b_csr.nnz,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Bcast(
		b_csr.ColInd.data,
		b_csr.nnz,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Bcast(
		b_csr.Val.data,
		b_csr.nnz,
		MPI_FLOAT,
		0,
		MPI_COMM_WORLD);

	ScsrInit(&amp;b_csr);
	ScsrMulScsr(&amp;a_csr_local, &amp;b_csr, &amp;c_csr_local);

	ScooFree(&amp;a_csr_local);
	ScooFree(&amp;b_csr);

	c_csr.m = c_csr_local.m;
	c_csr.n = c_csr_local.n;

	IntVector count, disp;
	IntVectorInit(&amp;count, comSize);
	IntVectorInit(&amp;disp, comSize);

	MPI_Gather(
		&amp;c_csr_local.nnz,
		1,
		MPI_INT,
		count.data,
		1,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	if (!comRank)
	{
		for (int i = disp.data[0] = 0; i &lt; comSize - 1; ++i)
			disp.data[i + 1] = disp.data[i] + count.data[i];
		c_csr.nnz = disp.data[comSize - 1] + count.data[comSize - 1];
		ScooMalloc(&amp;c_csr);
	}

	MPI_Gatherv(
		c_csr_local.RowInd.data,
		c_csr_local.nnz,
		MPI_INT,
		c_csr.RowInd.data,
		count.data,
		disp.data,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Gatherv(
		c_csr_local.ColInd.data,
		c_csr_local.nnz,
		MPI_INT,
		c_csr.ColInd.data,
		count.data,
		disp.data,
		MPI_INT,
		0,
		MPI_COMM_WORLD);

	MPI_Gatherv(
		c_csr_local.Val.data,
		c_csr_local.nnz,
		MPI_FLOAT,
		c_csr.ColInd.data,
		count.data,
		disp.data,
		MPI_FLOAT,
		0,
		MPI_COMM_WORLD);

	ScooFree(&amp;c_csr_local);
	IntVectorFree(&amp;count);
	IntVectorFree(&amp;disp);

	if (!comRank)
	{
		ScooFree(&amp;a_csr);
		ScsrInit(&amp;c_csr);
		ScooWrite(&amp;c_csr, stdout);
		ScooFree(&amp;c_csr);
	}

	MPI_Finalize();
}
</code></pre>

<h3 id="cuda-算法sparsescsrmm_cudacu">CUDA 算法<code>sparseScsrmm_cuda.cu</code></h3>

<p>终端执行下述指令，可以计时执行并将结果写入<code>sparseScsrmm_cuda_out.txt</code>。</p>

<pre><code class="language-bash">nvcc sparseScsrmm_cuda.cu -o sparseScsrmm_cuda
time ./sparseScsrmm_cuda matrix12.mat matrix.mat &gt; sparseScsrmm_cuda_out.txt
</code></pre>

<pre><code class="language-c">#include "WuKSPARSE.h"
void __global__ cuScsrMulScs(
	const int *a_csr_RowPtr,
	const int *a_csr_CowInd,
	const float *a_csr_Val,
	const int *b_csc_ColPtr,
	const int *b_csc_RowInd,
	const float *b_csc_Val,
	float *c,
	int m,
	int n)
{
	int
		i = blockIdx.x * blockDim.x + threadIdx.x,
		j = blockIdx.y * blockDim.y + threadIdx.y;
	float res = 0;
	for (int
			 kb = b_csc_ColPtr[j],
			 ka = a_csr_RowPtr[i];
		 kb &lt; b_csc_ColPtr[j + 1] &amp;&amp;
		 ka &lt; a_csr_RowPtr[i + 1];
		 ++kb)
	{
		while (a_csr_CowInd[ka] &lt; b_csc_RowInd[kb])
			++ka;
		while (a_csr_CowInd[ka] == b_csc_RowInd[kb])
			res += a_csr_Val[ka] * b_csc_Val[kb], ++ka;
	}
	c[i * n + j] = res;
}
void ScsrMulScsr(const Scoo *a_csr, const Scoo *b_csr, Scoo *c_csr)
{
	Scoo B_csc;
	ScooToScsc(b_csr, &amp;B_csc);

	int
		*a_RowPtr,
		*a_ColInd,
		*b_ColPtr,
		*b_RowInd;
	float
		*a_Val,
		*b_Val,
		*d_c;

	cudaMalloc(&amp;a_RowPtr, sizeof(int) * (a_csr-&gt;m + 1));
	cudaMemcpy(a_RowPtr, a_csr-&gt;RowPtr.data, sizeof(int) * (a_csr-&gt;m + 1), cudaMemcpyHostToDevice);

	cudaMalloc(&amp;a_ColInd, sizeof(int) * a_csr-&gt;nnz);
	cudaMemcpy(a_ColInd, a_csr-&gt;ColInd.data, sizeof(int) * a_csr-&gt;nnz, cudaMemcpyHostToDevice);

	cudaMalloc(&amp;a_Val, sizeof(float) * a_csr-&gt;nnz);
	cudaMemcpy(a_Val, a_csr-&gt;Val.data, sizeof(float) * a_csr-&gt;nnz, cudaMemcpyHostToDevice);

	cudaMalloc(&amp;b_ColPtr, sizeof(int) * (B_csc.n + 1));
	cudaMemcpy(b_ColPtr, B_csc.ColPtr.data, sizeof(int) * (B_csc.n + 1), cudaMemcpyHostToDevice);

	cudaMalloc(&amp;b_RowInd, sizeof(int) * B_csc.nnz);
	cudaMemcpy(b_RowInd, B_csc.RowInd.data, sizeof(int) * B_csc.nnz, cudaMemcpyHostToDevice);

	cudaMalloc(&amp;b_Val, sizeof(float) * B_csc.nnz);
	cudaMemcpy(b_Val, B_csc.Val.data, sizeof(float) * B_csc.nnz, cudaMemcpyHostToDevice);

	cudaMalloc(&amp;d_c, sizeof(float) * a_csr-&gt;m * B_csc.n);

	dim3
		block(16, 16),
		grid(a_csr-&gt;m / block.x, B_csc.n / block.y);

	cuScsrMulScs&lt;&lt;&lt;grid, block&gt;&gt;&gt;(
		a_RowPtr,
		a_ColInd,
		a_Val,
		b_ColPtr,
		b_RowInd,
		b_Val,
		d_c,
		a_csr-&gt;m,
		B_csc.n);

	FloatVector c;
	FloatVectorInit(&amp;c, a_csr-&gt;m * B_csc.n);
	cudaMemcpy(c.data, d_c, sizeof(float) * a_csr-&gt;m * B_csc.n, cudaMemcpyDeviceToHost);

	cudaFree(a_RowPtr);
	cudaFree(a_ColInd);
	cudaFree(b_ColPtr);
	cudaFree(b_RowInd);
	cudaFree(a_Val);
	cudaFree(b_Val);
	cudaFree(d_c);

	c_csr-&gt;m = a_csr-&gt;m;
	c_csr-&gt;n = B_csc.n;
	c_csr-&gt;nnz = 0;
	ScooMalloc(c_csr);

	for (int i = 0; i &lt; c_csr-&gt;m; ++i)
		for (int j = 0; j &lt; c_csr-&gt;n; ++j)
			if (c.data[i * c_csr-&gt;n + j])
				ScooPushBack(c_csr, i, j, c.data[i * c_csr-&gt;n + j]);
	FloatVectorFree(&amp;c);
	ScooFree(&amp;B_csc);
	ScsrInit(c_csr);
}
int main(int argc, char **argv)
{
	Scoo a_coo, b_coo, a_csr, b_csr, c_csr;

	ScooRead(&amp;a_coo, fopen(argv[1], "r"));
	ScooRead(&amp;b_coo, fopen(argv[2], "r"));

	ScooToScsr(&amp;a_coo, &amp;a_csr);
	ScooToScsr(&amp;b_coo, &amp;b_csr);

	ScooFree(&amp;a_coo);
	ScooFree(&amp;b_coo);

	ScsrMulScsr(&amp;a_csr, &amp;b_csr, &amp;c_csr);

	ScooWrite(&amp;c_csr, stdout);

	ScooFree(&amp;a_csr);
	ScooFree(&amp;b_csr);
	ScooFree(&amp;c_csr);
}
</code></pre>

<h3 id="稀疏矩阵处理库wuksparseh">稀疏矩阵处理库<code>WuKSPARSE.h</code></h3>

<pre><code class="language-c">#ifndef __WuKSPARSE_hpp__
#define __WuKSPARSE_hpp__
#include &lt;stdio.h&gt;
#include "WuKfloatVector.h"
#include "WuKintVector.h"
typedef struct Scoo
{
	int
		m,   //行
		n,   //列
		nnz; //非零元素数量
	IntVector
		RowPtr, //大小m+1
		ColPtr, //大小n+1
		RowInd, //大小nnz，行坐标
		ColInd; //大小nnz，列坐标
	FloatVector
		Val; //大小为nnz
} Scoo;
void ScooFree(Scoo *a)
{
	IntVectorFree(&amp;a-&gt;RowPtr);
	IntVectorFree(&amp;a-&gt;ColPtr);
	IntVectorFree(&amp;a-&gt;RowInd);
	IntVectorFree(&amp;a-&gt;ColInd);
	FloatVectorFree(&amp;a-&gt;Val);
}
void ScooMalloc(Scoo *a)
{
	IntVectorInit(&amp;a-&gt;RowPtr, a-&gt;m + 1);
	IntVectorInit(&amp;a-&gt;ColPtr, a-&gt;n + 1);
	IntVectorInit(&amp;a-&gt;RowInd, a-&gt;nnz);
	IntVectorInit(&amp;a-&gt;ColInd, a-&gt;nnz);
	FloatVectorInit(&amp;a-&gt;Val, a-&gt;nnz);
}
void ScooPushBack(Scoo *a, int r, int c, float v)
{
	IntVectorPushBack(&amp;a-&gt;RowInd, r);
	IntVectorPushBack(&amp;a-&gt;ColInd, c);
	FloatVectorPushBack(&amp;a-&gt;Val, v);
	++a-&gt;nnz;
}
void ScooRead(Scoo *a, FILE *f)
{
#define MAXLEN 511
	for (char s[MAXLEN]; fgets(s, MAXLEN, f) &amp;&amp; !feof(f);)
		if (s[0] != '%')
		{
			int nnz;
			sscanf(s, "%d%d%d", &amp;a-&gt;m, &amp;a-&gt;n, &amp;nnz);
			a-&gt;nnz = 0;
			ScooMalloc(a);
			for (int line = 0; line &lt; nnz; ++line)
			{
				int r, c;
				float v;
				fscanf(f, "%d%d%f", &amp;r, &amp;c, &amp;v);
				if (0 &lt;= r &amp;&amp; r &lt; a-&gt;m &amp;&amp;
					0 &lt;= c &amp;&amp; c &lt; a-&gt;n)
					ScooPushBack(a, r, c, v);
			}
			break;
		}
#undef MAXLEN
}
void ScooWrite(const Scoo *a, FILE *f)
{
	fprintf(
		f,
		"%%MatrixMarket matrix coordinate real general\n%d %d %d\n",
		a-&gt;m,
		a-&gt;n,
		a-&gt;nnz);
	for (int j = 0; j &lt; a-&gt;nnz; ++j)
		fprintf(
			f,
			"%d %d %f\n",
			a-&gt;RowInd.data[j],
			a-&gt;ColInd.data[j],
			a-&gt;Val.data[j]);
}
void ScsrInit(Scoo *a)
{
	int cur = 0;
	for (int i = a-&gt;RowPtr.data[0] = 0; i &lt; a-&gt;nnz; ++i)
		for (; cur &lt; a-&gt;RowInd.data[i]; ++cur)
			a-&gt;RowPtr.data[cur + 1] = i;
	for (; cur &lt; a-&gt;m; ++cur)
		a-&gt;RowPtr.data[cur + 1] = a-&gt;nnz;
}
void ScooToScsr(const Scoo *a, Scoo *b)
{
	IntVector beg, s;
	IntVectorInit(&amp;beg, a-&gt;nnz);
	IntVectorInit(&amp;s, 2);
	for (int i = 0; i &lt; a-&gt;nnz; ++i)
		beg.data[i] = i;
	s.data[0] = 0, s.data[1] = a-&gt;nnz - 1;
	while (s.size)
	{
		int right = s.data[--s.size], left = s.data[--s.size], l = left, r = right, pivot = beg.data[l];
		while (l &lt; r)
		{
#define LESS(x, y) (a-&gt;RowInd.data[x] &lt; a-&gt;RowInd.data[y] || a-&gt;RowInd.data[x] == a-&gt;RowInd.data[y] &amp;&amp; a-&gt;ColInd.data[x] &lt; a-&gt;ColInd.data[y])
			while (l &lt; r &amp;&amp; !LESS(beg.data[r], pivot))
				--r;
			beg.data[l] = beg.data[r];
			while (l &lt; r &amp;&amp; !LESS(pivot, beg.data[l]))
				++l;
			beg.data[r] = beg.data[l];
#undef LESS
		}
		beg.data[l] = pivot;
		if (l - 1 &gt; left)
		{
			IntVectorPushBack(&amp;s, left);
			IntVectorPushBack(&amp;s, l - 1);
		}
		if (l + 1 &lt; right)
		{
			IntVectorPushBack(&amp;s, l + 1);
			IntVectorPushBack(&amp;s, right);
		}
	}
	IntVectorFree(&amp;s);
	*b = *a;
	ScooMalloc(b);
	for (int i = 0; i &lt; b-&gt;nnz; ++i)
	{
		b-&gt;RowInd.data[i] = a-&gt;RowInd.data[beg.data[i]];
		b-&gt;ColInd.data[i] = a-&gt;ColInd.data[beg.data[i]];
		b-&gt;Val.data[i] = a-&gt;Val.data[beg.data[i]];
	}
	ScsrInit(b);
}
void ScscInit(Scoo *a)
{
	int cur = 0;
	for (int i = a-&gt;ColPtr.data[0] = 0; i &lt; a-&gt;nnz; ++i)
		for (; cur &lt; a-&gt;ColInd.data[i]; ++cur)
			a-&gt;ColPtr.data[cur + 1] = i;
	for (; cur &lt; a-&gt;m; ++cur)
		a-&gt;ColPtr.data[cur + 1] = a-&gt;nnz;
}
void ScooToScsc(const Scoo *a, Scoo *b)
{
	IntVector beg, s;
	IntVectorInit(&amp;beg, a-&gt;nnz);
	IntVectorInit(&amp;s, 2);
	for (int i = 0; i &lt; a-&gt;nnz; ++i)
		beg.data[i] = i;
	s.data[0] = 0, s.data[1] = a-&gt;nnz - 1;
	while (s.size)
	{
		int right = s.data[--s.size], left = s.data[--s.size], l = left, r = right, pivot = beg.data[l];
		while (l &lt; r)
		{
#define LESS(x, y) (a-&gt;ColInd.data[x] &lt; a-&gt;ColInd.data[y] || a-&gt;ColInd.data[x] == a-&gt;ColInd.data[y] &amp;&amp; a-&gt;RowInd.data[x] &lt; a-&gt;RowInd.data[y])
			while (l &lt; r &amp;&amp; !LESS(beg.data[r], pivot))
				--r;
			beg.data[l] = beg.data[r];
			while (l &lt; r &amp;&amp; !LESS(pivot, beg.data[l]))
				++l;
			beg.data[r] = beg.data[l];
#undef LESS
		}
		beg.data[l] = pivot;
		if (l - 1 &gt; left)
		{
			IntVectorPushBack(&amp;s, left);
			IntVectorPushBack(&amp;s, l - 1);
		}
		if (l + 1 &lt; right)
		{
			IntVectorPushBack(&amp;s, l + 1);
			IntVectorPushBack(&amp;s, right);
		}
	}
	IntVectorFree(&amp;s);
	*b = *a;
	ScooMalloc(b);
	for (int i = 0; i &lt; b-&gt;nnz; ++i)
	{
		b-&gt;RowInd.data[i] = a-&gt;RowInd.data[beg.data[i]];
		b-&gt;ColInd.data[i] = a-&gt;ColInd.data[beg.data[i]];
		b-&gt;Val.data[i] = a-&gt;Val.data[beg.data[i]];
	}
	ScscInit(b);
	IntVectorFree(&amp;beg);
}
#endif
</code></pre>

<h3 id="浮点动态向量库wukfloatvectorh">浮点动态向量库<code>WuKfloatVector.h</code></h3>

<pre><code class="language-c">#ifndef __WuKfloatVector_h__
#define __WuKfloatVector_h__
#include &lt;malloc.h&gt;
#include &lt;string.h&gt;
typedef struct FloatVector
{
    int size, cap;
    float *data;
} FloatVector;
void FloatVectorFree(FloatVector *v) { free(v-&gt;data); }
void FloatVectorInit(FloatVector *v, int size)
{
    v-&gt;size = v-&gt;cap = size;
    if (v-&gt;cap &lt; 1)
        v-&gt;cap = 1;
    v-&gt;data = (float *)malloc(sizeof(float) * v-&gt;cap);
}
void FloatVectorPushBack(FloatVector *v, float val)
{
    while (v-&gt;cap &lt;= v-&gt;size)
    {
        FloatVector v_new;
        FloatVectorInit(&amp;v_new, v-&gt;cap &lt;&lt; 1);
        memcpy(v_new.data, v-&gt;data, sizeof(float) * v-&gt;size);
        FloatVectorFree(v);
        *v = v_new;
        v-&gt;size &gt;&gt;= 1;
    }
    v-&gt;data[v-&gt;size++] = val;
}
#endif
</code></pre>

<h3 id="整型动态向量库wukintvectorh">整型动态向量库<code>WuKintVector.h</code></h3>

<pre><code class="language-c">#ifndef __WuKintVector_h__
#define __WuKintVector_h__
#include &lt;malloc.h&gt;
#include &lt;string.h&gt;
typedef struct IntVector
{
    int size, cap;
    int *data;
} IntVector;
void IntVectorFree(IntVector *v) { free(v-&gt;data); }
void IntVectorInit(IntVector *v, int size)
{
    v-&gt;size = v-&gt;cap = size;
    if (v-&gt;cap &lt; 1)
        v-&gt;cap = 1;
    v-&gt;data = (int *)malloc(sizeof(int) * v-&gt;cap);
}
void IntVectorPushBack(IntVector *v, int val)
{
    while (v-&gt;cap &lt;= v-&gt;size)
    {
        IntVector v_new;
        IntVectorInit(&amp;v_new, v-&gt;cap &lt;&lt; 1);
        memcpy(v_new.data, v-&gt;data, sizeof(int) * v-&gt;size);
        IntVectorFree(v);
        *v = v_new;
        v-&gt;size &gt;&gt;= 1;
    }
    v-&gt;data[v-&gt;size++] = val;
}
#endif
</code></pre>

</div>
<div class="v">
  <i class="fas fa-spinner fa-pulse"></i>
</div>
<script
  src='https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js'
  defer='defer'
  onload='
    new Valine({
      "el": document.getElementsByClassName("v")[0],
      "appId": "9hABRddSuEkTgqLrt1VSK5B1-gzGzoHsz",
      "appKey": "NJ7RwmgrxsF7KDzlqU7YewlL",
      "placeholder": "在这里评论吧！填写邮箱可以获得 Gravatar 头像和回复通知哦",
      "requiredFields": ["nick","mail"],
      "visitor": true,
      "recordIP": true
    })'
></script>

</div>
  </div>
  
  <label for="sidebar-checkbox" class="sidebar-toggle"></label>
  
</body>

</html>