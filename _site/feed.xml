<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-10T01:29:44+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">wu-kan</title><subtitle>SYSU超算17级在读&lt;br/&gt;
永远喜欢水野爱&lt;br/&gt;
田宫例四驱车&lt;br/&gt;
ASC&lt;br/&gt;
&lt;a href=&quot;mailto:i@wu-kan.cn&quot;&gt;
  &lt;i class=&quot;fas fa-envelope&quot;&gt;&lt;/i&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/wu-kan&quot;&gt;
  &lt;i class=&quot;fab fa-github&quot;&gt;&lt;/i&gt;
&lt;/a&gt;
&lt;a href=&quot;https://codeforces.com/profile/WuK&quot;&gt;
  &lt;i class=&quot;fas fa-chart-bar&quot;&gt;&lt;/i&gt;
&lt;/a&gt;
&lt;a href=&quot;https://vjudge.net/user/WuK&quot;&gt;
  &lt;i class=&quot;fas fa-smile&quot;&gt;&lt;/i&gt;
&lt;/a&gt;
&lt;a href=&quot;https://www.zhihu.com/people/wu.kan/activities&quot;&gt;
  &lt;i class=&quot;fab fa-zhihu&quot;&gt;&lt;/i&gt;
&lt;/a&gt;
&lt;iframe
  src=&quot;https://music.163.com/outchain/player?type=0&amp;id=155059595&amp;auto=0&amp;height=32&quot;
  width=100%
  height=52
  frameborder=&quot;no&quot;
  border=&quot;0&quot;
  marginwidth=&quot;0&quot;
  marginheight=&quot;0&quot;
&gt;&lt;/iframe&gt;
</subtitle><entry><title type="html">编译原理（二）</title><link href="http://localhost:4000/_posts/2020-04-28-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-%E4%BA%8C/" rel="alternate" type="text/html" title="编译原理（二）" /><published>2020-04-28T00:00:00+08:00</published><updated>2020-04-28T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86(%E4%BA%8C)</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-28-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-%E4%BA%8C/">&lt;p&gt;由画图工具所限，以下均以 s0 作为起始状态，圆形作为接收状态。&lt;/p&gt;

&lt;h2 id=&quot;考虑以下-nfa&quot;&gt;考虑以下 NFA&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
s0--ε--&amp;gt;s1
s1--a--&amp;gt;s1
s1--b--&amp;gt;s2
s2--a--&amp;gt;s2
s2--b--&amp;gt;s1
s0--ε--&amp;gt;s3
s3--b--&amp;gt;s3
s3--a--&amp;gt;s4
s4--b--&amp;gt;s4
s4--a--&amp;gt;s3
s1((s1))
s3((s3))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;这一-nfa-接受什么语言用自然语言描述&quot;&gt;这一 NFA 接受什么语言（用自然语言描述）&lt;/h3&gt;

&lt;p&gt;由 a 和 b 构成的字符串，a 或 b 出现了偶数次。&lt;/p&gt;

&lt;h3 id=&quot;构造接受同一语言的-dfa&quot;&gt;构造接受同一语言的 DFA&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
s0--a--&amp;gt;s1
s0--b--&amp;gt;s2
s1--a--&amp;gt;s0
s1--b--&amp;gt;s3
s2--b--&amp;gt;s0
s2--a--&amp;gt;s3
s3--b--&amp;gt;s1
s3--a--&amp;gt;s2
s0((s0))
s1((s1))
s2((s2))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;正则语言补运算&quot;&gt;正则语言补运算&lt;/h2&gt;

&lt;h3 id=&quot;画出一个-dfa该-dfa-恰好识别所有含有-011-子串的二进制串&quot;&gt;画出一个 DFA，该 DFA 恰好识别所有含有 011 子串的二进制串&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
s0--0--&amp;gt;s1
s0--1--&amp;gt;s0
s1--0--&amp;gt;s1
s1--1--&amp;gt;s2
s2--0--&amp;gt;s1
s2--1--&amp;gt;s3
s3--0--&amp;gt;s3
s3--1--&amp;gt;s3
s3((s3))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;画出一个-dfa该-dfa-恰好识别所有不含-011-子串的二进制串&quot;&gt;画出一个 DFA，该 DFA 恰好识别所有不含 011 子串的二进制串&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
s0--0--&amp;gt;s1
s0--1--&amp;gt;s0
s1--0--&amp;gt;s1
s1--1--&amp;gt;s2
s2--0--&amp;gt;s1
s2--1--&amp;gt;s3
s3--0--&amp;gt;s3
s3--1--&amp;gt;s3
s0((s0))
s1((s1))
s2((s2))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;再证明对任一正则表达式-r一定存在另一正则表达式-r使得-lr-是-lr-的补集&quot;&gt;再证明：对任一正则表达式 $R$，一定存在另一正则表达式 $R’$，使得 $L(R’)$ 是 $L(R)$ 的补集&lt;/h3&gt;

&lt;p&gt;因为正则表达式和 DFA 是等价的，不妨设识别 $L(R)$ 的 DFA 为 $M$。由前两问容易发现，将 $M$ 中所有接收状态与非接收状态反转可得到 $M’$，它将识别 $L(R)$ 的补集 $L(R’)$。再次利用正则表达式与 DFA 的等价性可以证明并求得 $R’$。&lt;/p&gt;

&lt;h2 id=&quot;设有一门小小语言仅含-zo斜杠3-个符号该语言中的一个注释以一个o-为开始标记以此后出现的第一个-o为结束标记&quot;&gt;设有一门小小语言仅含 &lt;code&gt;z&lt;/code&gt;、&lt;code&gt;o&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt;（斜杠）3 个符号，该语言中的一个注释以一个&lt;code&gt;/o&lt;/code&gt; 为开始标记，以此后出现的第一个 &lt;code&gt;o/&lt;/code&gt;为结束标记&lt;/h2&gt;

&lt;h3 id=&quot;请给出单个正则表达式它仅与一个完整的注释匹配除此之外不匹配任何其他串书写正则表达式时要求仅使用最基本的正则表达式算子epsilonvert&quot;&gt;请给出单个正则表达式，它仅与一个完整的注释匹配，除此之外不匹配任何其他串。书写正则表达式时，要求仅使用最基本的正则表达式算子（$\epsilon$，$\vert$，*，+，？）&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;/o((o*z)|/)*o+/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;给出识别上述正则表达式所定义语言的确定有限自动机dfa-你可根据问题直接构造-dfa不必运用机械的算法从上一小题的正则表达式转换得到-dfa&quot;&gt;给出识别上述正则表达式所定义语言的确定有限自动机（DFA）. 你可根据问题直接构造 DFA，不必运用机械的算法从上一小题的正则表达式转换得到 DFA&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
s0--/--&amp;gt;s1
s1--&quot;o&quot;--&amp;gt;s2
s2--z--&amp;gt;s2
s2--/--&amp;gt;s2
s2--&quot;o&quot;--&amp;gt;s3
s3--z--&amp;gt;s2
s3--&quot;o&quot;--&amp;gt;s3
s3--/--&amp;gt;s4
s4((s4))
&lt;/code&gt;&lt;/pre&gt;</content><author><name></name></author><category term="编译原理" /><summary type="html">由画图工具所限，以下均以 s0 作为起始状态，圆形作为接收状态。</summary></entry><entry><title type="html">词法分析</title><link href="http://localhost:4000/_posts/2020-04-28-%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/" rel="alternate" type="text/html" title="词法分析" /><published>2020-04-28T00:00:00+08:00</published><updated>2020-04-28T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-28-%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/">&lt;h2 id=&quot;dfa-识别语言&quot;&gt;&lt;a href=&quot;http://soj.acmm.club/show_problem.php?pid=1000&amp;amp;cid=2834&quot;&gt;DFA 识别语言&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Time Limit: 1sec Memory Limit:256MB&lt;/p&gt;

&lt;h3 id=&quot;description&quot;&gt;Description&lt;/h3&gt;

&lt;p&gt;对于给出的 DFA 和输入的字符串，判断字符串是否是 DFA 识别的语言。&lt;/p&gt;

&lt;h3 id=&quot;input&quot;&gt;Input&lt;/h3&gt;

&lt;p&gt;输入有多组数据。每组数据的第一行是两个整数 N（N&amp;lt;=50）和 M（M&amp;lt;=26），分别代表 DFA 的状态数和字母表的字符数。DFA 的 N 个状态用整数 0 ～ N-1 表示。状态 0 为起始状态。字母表包含的字符是小写英文字母的前 M 个字符。接下来的 N 行，每行有 M 个整数。其中第 i 行第 j 列的数字 k，表示 DFA 在状态 i-1，当输入符号为第 j 个小写字母时，迁移到状态 k。接下来的一行包含若干个整数，代表 DFA 的接受状态，这一行以-1 结尾。接下来的每一行是一个待识别的字符串，字符串的长度在 1 到 50 之间且只含有小写字母。字符串”#”代表本组数据结束。N=M=0 表示输入结束。&lt;/p&gt;

&lt;h3 id=&quot;output&quot;&gt;Output&lt;/h3&gt;

&lt;p&gt;对于每个待识别的字符串，如果能被给出的DFA识别，输出YES；否则输出NO。&lt;/p&gt;

&lt;h3 id=&quot;sample-input&quot;&gt;Sample Input&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;4 2
1 0
1 2
1 3
1 0
3 -1
aaabb
abbab
abbaaabb
abbb
#
1 3
0 0 0
0 -1
cacba
#
0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;sample-output&quot;&gt;Sample output&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;YES
NO
YES
NO
YES
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;hint&quot;&gt;Hint&lt;/h3&gt;

&lt;p&gt;你只需要实现课本Figure 3.27的程序就可以。&lt;/p&gt;

&lt;h3 id=&quot;solution&quot;&gt;Solution&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;#include &amp;lt;bits/stdc++.h&amp;gt;
using namespace std;
struct DeterministicFiniteAutomaton
{
    struct State
    {
        vector&amp;lt;int&amp;gt; trans;
        int isAccepted;
        State(int m) : trans(m, -1), isAccepted(0) {}
    };
    vector&amp;lt;State&amp;gt; state;
    DeterministicFiniteAutomaton(int n, int m) : state(n, State(m)) {}
    int ask(const string &amp;amp;s)
    {
        int cur = 0;
        for (int i = 0; i &amp;lt; s.size(); ++i)
        {
            cur = state[cur].trans[s[i] - 'a'];
            if (cur &amp;lt; 0)
                return 0;
        }
        return state[cur].isAccepted;
    }
};
int main()
{
    for (int n, m; cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m &amp;amp;&amp;amp; n &amp;amp;&amp;amp; m;)
    {
        DeterministicFiniteAutomaton dfa(n, m);
        for (int i = 0, k; i &amp;lt; n; ++i)
            for (int j = 0; j &amp;lt; m; ++j)
            {
                cin &amp;gt;&amp;gt; k;
                dfa.state[i].trans[j] = k;
            }
        for (int k; cin &amp;gt;&amp;gt; k &amp;amp;&amp;amp; k &amp;gt;= 0;)
            dfa.state[k].isAccepted = 1;
        for (string s; cin &amp;gt;&amp;gt; s &amp;amp;&amp;amp; s != &quot;#&quot;;)
            cout &amp;lt;&amp;lt; (dfa.ask(s) ? &quot;YES\n&quot; : &quot;NO\n&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;nfa-识别语言&quot;&gt;&lt;a href=&quot;http://soj.acmm.club/show_problem.php?pid=1001&amp;amp;cid=2834&quot;&gt;NFA 识别语言&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Time Limit: 1sec Memory Limit:256MB&lt;/p&gt;

&lt;h3 id=&quot;description-1&quot;&gt;Description&lt;/h3&gt;

&lt;p&gt;对于给出的 NFA 和输入的字符串，判断字符串是否是 NFA 识别的语言。&lt;/p&gt;

&lt;h3 id=&quot;input-1&quot;&gt;Input&lt;/h3&gt;

&lt;p&gt;输入有多组数据。每组数据的第一行是两个整数 N（N&amp;lt;=50）和 M（M&amp;lt;=27），表示 NFA 有 N 个状态，以及字母表有 M-1 个字符。NFA 的 N 个状态用整数 0 ～ N-1 表示，状态 0 为起始状态。字母表包含小写英文字母的前 M-1 个字符。接下来的 N 行，每行有 M 个整数集（用’{‘和’}’括起）。其中，第 i 行第 1 列的整数集表示在状态 i-1 时，对应于 є（空串）的状态迁移；第 i 行第 j（j&amp;gt;1）列的整数集，表示 NFA 在状态 i-1，当输入符号为第 j-1 个小写字母时，迁移到的状态集。接下来的一行包含若干个整数，代表 NFA 的接受状态，这一行以-1 结尾。接下来的每一行是一个待识别的字符串，字符串的长度在 1 到 50 之间且只含有小写字母。字符串”#”代表本组数据结束。N=M=0 表示输入结束。&lt;/p&gt;

&lt;h3 id=&quot;output-1&quot;&gt;Output&lt;/h3&gt;

&lt;p&gt;对于每个待识别的字符串，如果能被给出的 NFA 识别，输出 YES；否则输出 NO。&lt;/p&gt;

&lt;h3 id=&quot;sample-input-1&quot;&gt;Sample Input&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;4 3
{} {0,1} {0}
{} {} {2}
{} {} {3}
{} {} {}
3 -1
aaabb
abbab
abbaaabb
abbb
#
0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;sample-output-1&quot;&gt;Sample Output&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;YES
NO
YES
NO
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;hint-1&quot;&gt;Hint&lt;/h3&gt;

&lt;p&gt;输入样例是课本Figure 3.24的NFA。你需要实现的是课本Figure 3.33和3.37的算法。&lt;/p&gt;

&lt;h3 id=&quot;solution-1&quot;&gt;Solution&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;#include &amp;lt;bits/stdc++.h&amp;gt;
using namespace std;
struct NondeterministicFiniteAutomaton
{
    struct State
    {
        vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; trans;
        int isAccepted;
        State(int m) : trans(m), isAccepted(0) {}
    };
    vector&amp;lt;State&amp;gt; state;
    NondeterministicFiniteAutomaton(int n, int m) : state(n, State(m)) {}
    vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; vis;
    int ask(const string &amp;amp;s, int i = 0, int cur = 0)
    {
        if (vis[i][cur])
            return 0;
        vis[i][cur] = 1;
        if (i == s.size() &amp;amp;&amp;amp; state[cur].isAccepted)
            return 1;
        for (int j : state[cur].trans.back())
            if (ask(s, i, j))
                return 1;
        if (i &amp;lt; s.size())
            for (int j : state[cur].trans[s[i] - 'a'])
                if (ask(s, i + 1, j))
                    return 1;
        return 0;
    }
};
int main()
{
    for (int n, m; cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m &amp;amp;&amp;amp; n &amp;amp;&amp;amp; m;)
    {
        NondeterministicFiniteAutomaton dfa(n, m);
        for (int i = 0; i &amp;lt; n; ++i)
            for (int j = 0; j &amp;lt; m; ++j)
            {
                string s;
                cin &amp;gt;&amp;gt; s;
                int x = -1;
                for (int k = 1; k &amp;lt; s.size(); ++k)
                {
                    if (isdigit(s[k]))
                    {
                        if (x &amp;lt; 0)
                            x = 0;
                        x = x * 10 + s[k] - '0';
                    }
                    else if (x &amp;gt;= 0)
                    {
                        dfa.state[i].trans[(j + m - 1) % m].push_back(x);
                        x = -1;
                    }
                }
            }
        for (int k; cin &amp;gt;&amp;gt; k &amp;amp;&amp;amp; k &amp;gt;= 0;)
            dfa.state[k].isAccepted = 1;
        for (string s; cin &amp;gt;&amp;gt; s &amp;amp;&amp;amp; s != &quot;#&quot;;)
        {
            dfa.vis.assign(s.size() + 1, vector&amp;lt;int&amp;gt;(n, 0));
            cout &amp;lt;&amp;lt; (dfa.ask(s) ? &quot;YES\n&quot; : &quot;NO\n&quot;);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;</content><author><name></name></author><category term="编译原理" /><summary type="html">DFA 识别语言</summary></entry><entry><title type="html">软件工程理论与实践（四）</title><link href="http://localhost:4000/_posts/2020-04-27-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E5%9B%9B/" rel="alternate" type="text/html" title="软件工程理论与实践（四）" /><published>2020-04-27T00:00:00+08:00</published><updated>2020-04-27T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5(%E5%9B%9B)</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-27-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E5%9B%9B/">&lt;h2 id=&quot;类图有几个图形符号画出一个任意场景的类图并简单解释&quot;&gt;类图有几个图形符号？画出一个任意场景的类图，并简单解释&lt;/h2&gt;

&lt;h2 id=&quot;uml-中的包是什么样子的其作用是什么uml-中有-package-diagram-吗&quot;&gt;UML 中的包是什么样子的，其作用是什么？UML 中有 package diagram 吗&lt;/h2&gt;

&lt;h2 id=&quot;简述软件工程的-6-个最佳实践&quot;&gt;简述软件工程的 6 个最佳实践&lt;/h2&gt;

&lt;h2 id=&quot;解释对象类继承聚合多态封装&quot;&gt;解释对象、类、继承、聚合、多态、封装&lt;/h2&gt;</content><author><name></name></author><category term="软件工程理论与实践" /><summary type="html">类图有几个图形符号？画出一个任意场景的类图，并简单解释</summary></entry><entry><title type="html">软件工程理论与实践（三）</title><link href="http://localhost:4000/_posts/2020-04-26-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E4%B8%89/" rel="alternate" type="text/html" title="软件工程理论与实践（三）" /><published>2020-04-26T00:00:00+08:00</published><updated>2020-04-26T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5(%E4%B8%89)</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-26-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E4%B8%89/">&lt;h2 id=&quot;uml-中活动图是在用在生命周期中的哪个阶段的用来做什么的有几个图形符号画出来它们表示什么含义&quot;&gt;UML 中活动图是在用在生命周期中的哪个阶段的、用来做什么的、有几个图形符号(画出来)、它们表示什么含义&lt;/h2&gt;

&lt;p&gt;活动图在用例规约阶段，用来写用例的流程（主流程、备选流程），有六个符号：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;实心圆圈：表示开始节点与结束节点&lt;/li&gt;
  &lt;li&gt;圆边矩形：表示 state&lt;/li&gt;
  &lt;li&gt;圆角矩形：表示 state&lt;/li&gt;
  &lt;li&gt;实心条：表示同步&lt;/li&gt;
  &lt;li&gt;缺角矩形：表示注释&lt;/li&gt;
  &lt;li&gt;菱形：表示判断&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;根据你自己的理解uml-对于软件项目的成功有什么价值写出-3-5-条&quot;&gt;根据你自己的理解，UML 对于软件项目的成功有什么价值？（写出 3-5 条）&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;把抽象的项目需求转换为直白的模型&lt;/li&gt;
  &lt;li&gt;可以清楚地把项目表现给客户&lt;/li&gt;
  &lt;li&gt;便于后期维护&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;画完用例图你要进行复审一般你检查哪些内容写出-3-5-条&quot;&gt;画完用例图，你要进行复审，一般你检查哪些内容？（写出 3-5 条）&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;所有用例是否出现&lt;/li&gt;
  &lt;li&gt;关系的对应关系是否正确&lt;/li&gt;
  &lt;li&gt;是否表达清晰&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;actor-表示角色其是外部环境怎样理解&quot;&gt;Actor 表示角色，其是“外部环境”，怎样理解&lt;/h2&gt;

&lt;p&gt;Actor 是指系统外的，在使用系统或与系统交互中所扮演的角色，所以不是系统内部的，算是外部条件&lt;/p&gt;</content><author><name></name></author><category term="软件工程理论与实践" /><summary type="html">UML 中活动图是在用在生命周期中的哪个阶段的、用来做什么的、有几个图形符号(画出来)、它们表示什么含义</summary></entry><entry><title type="html">编译原理（一）</title><link href="http://localhost:4000/_posts/2020-04-25-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-%E4%B8%80/" rel="alternate" type="text/html" title="编译原理（一）" /><published>2020-04-25T00:00:00+08:00</published><updated>2020-04-25T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86(%E4%B8%80)</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-25-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-%E4%B8%80/">&lt;h2 id=&quot;下列正则表达式定义了什么语言用尽可能简短的自然语言描述&quot;&gt;下列正则表达式定义了什么语言（用尽可能简短的自然语言描述）&lt;/h2&gt;

&lt;h3 id=&quot;babab&quot;&gt;&lt;code&gt;b*(ab*ab*)*&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;由 a 和 b 构成的字符串，a 出现了偶数次。&lt;/p&gt;

&lt;h3 id=&quot;caacbabccbbcaabc&quot;&gt;&lt;code&gt;c*a(a|c)*b(a|b|c)*|c*b(b|c)*a(a|b|c)*&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;由 a、b 和 c 构成的字符串，a 和 b 都至少出现一次。&lt;/p&gt;

&lt;h2 id=&quot;设字母表-sumab用正则表达式只使用-abepsilonvert描述下列语言&quot;&gt;设字母表 $\sum={a,b}$，用正则表达式（只使用 $a$，$b$，$\epsilon$，$\vert$，*，$+$，$？$）描述下列语言&lt;/h2&gt;

&lt;p&gt;注意：关于子串（substring）和子序列（subsequence）的区别可以参考课本第 119 页方框中的内容。&lt;/p&gt;

&lt;h3 id=&quot;不包含子串-ab-的所有字符串&quot;&gt;不包含子串 ab 的所有字符串&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;b*a*&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;不包含子串-abb-的所有字符串&quot;&gt;不包含子串 abb 的所有字符串&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;b*(ab?)*&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;不包含子序列-abb-的所有字符串&quot;&gt;不包含子序列 abb 的所有字符串&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;b*a*b?a*&lt;/code&gt;&lt;/p&gt;</content><author><name></name></author><category term="编译原理" /><summary type="html">下列正则表达式定义了什么语言（用尽可能简短的自然语言描述）</summary></entry><entry><title type="html">软件工程理论与实践（二）</title><link href="http://localhost:4000/_posts/2020-04-22-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E4%BA%8C/" rel="alternate" type="text/html" title="软件工程理论与实践（二）" /><published>2020-04-22T00:00:00+08:00</published><updated>2020-04-22T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5(%E4%BA%8C)</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-22-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E4%BA%8C/">&lt;h2 id=&quot;请解释何为制品&quot;&gt;请解释何为制品&lt;/h2&gt;

&lt;p&gt;制品是在软件分析、设计、实现等过程中产生的所有文本、代码。&lt;/p&gt;

&lt;h2 id=&quot;请阐述你知道的面向对象方法论-3-5-个&quot;&gt;请阐述你知道的面向对象方法论 3-5 个&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;面向对象的分析（OA）&lt;/li&gt;
  &lt;li&gt;面向对象的设计（OD）&lt;/li&gt;
  &lt;li&gt;面向对象的编程&lt;/li&gt;
  &lt;li&gt;面向对象的测试&lt;/li&gt;
  &lt;li&gt;面向对象的维护。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;基于面向对象的软件需求分析的步骤和制品是什么&quot;&gt;基于面向对象的软件需求分析的步骤和制品是什么&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;问题陈述，制品为：一段描述项目主要角色、主要功能、交互的其它系统、主要的非功能需求的文档&lt;/li&gt;
  &lt;li&gt;用例析取，制品为：用例图&lt;/li&gt;
  &lt;li&gt;用例归约，制品为：对本系统的用例进行详细描述的文档&lt;/li&gt;
  &lt;li&gt;补充归约，制品为：描述整个系统全局性的非功能需求的文档&lt;/li&gt;
  &lt;li&gt;术语表，制品为：定义项目文档中出现的读者可能不熟悉的术语的文档&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="软件工程理论与实践" /><summary type="html">请解释何为制品</summary></entry><entry><title type="html">软件工程理论与实践（一）</title><link href="http://localhost:4000/_posts/2020-04-20-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E4%B8%80/" rel="alternate" type="text/html" title="软件工程理论与实践（一）" /><published>2020-04-20T00:00:00+08:00</published><updated>2020-04-20T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5(%E4%B8%80)</id><content type="html" xml:base="http://localhost:4000/_posts/2020-04-20-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E4%B8%80/">&lt;h2 id=&quot;什么是软件危机结合软件危机的现象进行阐述&quot;&gt;什么是软件危机，结合软件危机的现象进行阐述&lt;/h2&gt;

&lt;p&gt;软件危机是计算机软件在它的开发和维护过程中所遇到的一系列严重问题。概括地说，主要包含两方面的问题：如何开发软件，怎样满足对软件日益增长的需求；如何维护数量不断膨胀的已有软件。&lt;/p&gt;

&lt;p&gt;软件危机的主要表现：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对软件开发成本和进度的估计常常很不准确。
实际成本比估计成本有可能高出一个数量级，实际进度比预期进度拖延几个月甚至几年的现象并不罕见。这种现象降低了开发组织的信誉。为赶进度和节约成本所采取的权宜之计往往又损害了软件产品的质量，从而不可避免地引起用户的不满。&lt;/li&gt;
  &lt;li&gt;用户对“已完成的”软件系统不满意的现象经常发生。
软件开发人员常常在对用户需求只有模糊的了解，甚至对所要解决的问题还没有确切认识的情况下，就仓促上阵匆忙着手编写程序。软件开发人员和用户之间的交流往往很不充分，“闭门造车”必然导致最终产品不符合用户实际需要。&lt;/li&gt;
  &lt;li&gt;软件产品的质量常常靠不住。
软件可靠性和质量保证的确切定量概念刚刚出现，软件质量保证技术（审查、复审和测试）还没有坚持不懈地应用到软件开发的全过程中，这些都会导致软件产品发生质量问题。&lt;/li&gt;
  &lt;li&gt;软件常常是不可维护的。
程序中的错误很难改正，实际上不可能使这些程序适应新的硬件环境，也不能根据用户的需求在原有程序中增加新的功能。&lt;/li&gt;
  &lt;li&gt;软件通常没有适当的文档资料。
软件不仅是程序，还应该有一整套文档资料。这些文档资料是在软件开发过程中产生出来的，而且应该是“最新的”（与代码完全一致）。缺乏文档必然给软件的开发和维护带来许多严重的困难和问题。&lt;/li&gt;
  &lt;li&gt;软件成本在计算机系统总成本中所占比例逐年上升。
随着微电子技术的进步和生产自动化程度的提高，硬件成本逐年下降，然而软件开发需要大量的人力，软件成本随着通货膨胀以及软件规模和数量的不断扩大而逐年上升。美国在 1995 年的调查表明，软件成本大约已占计算机系统总成本的 90%。
软件危机的出现，使得人们去寻找产生危机的内在原因，发现其原因可归纳为两方面，一方面是由软件生产本身存在着复杂性，另一方面却是与软件开发所使用的方法和技术有关。
软件工程正是为克服软件危机而提出的一种概念，并在实践中不断地探索它的原理，技术和方法。在此过程中，人们研究和借鉴了工程学的某些原理和方法，并形成了一门新的学科—软件工程学，但可惜的是时至今日人们并没有完全克服软件危机。&lt;/li&gt;
  &lt;li&gt;软件开发生产率提高的速度，远远跟不上计算机应用迅速普及深入的趋势&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;简述并分析软件危机产生的原因&quot;&gt;简述并分析软件危机产生的原因&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;与软件本身特点相关
    &lt;ol&gt;
      &lt;li&gt;软件不同于硬件，它是计算机系统的逻辑部件而不是物理部件。在写出程序代码并在计算机上试运行之前，软件开发过程的进展情况较难衡量。很难检验开发的正确性且软件开发的质量也较难评价。因此，控制软件开发过程相当困难。&lt;/li&gt;
      &lt;li&gt;此外，在软件运行过程中发现错误，很可能是遇到了一个在开发期间引入的、但在测试阶段没有能够检测出来的错误，所以软件维护常常意味着修改原来的设计。这样，维护的费用十分惊人，客观上使得软件较难维护。&lt;/li&gt;
      &lt;li&gt;软件规模庞大，而且程序复杂性将随着程序规模的增加而成指数上升。&lt;/li&gt;
      &lt;li&gt;对用户要求没有完整准确的认识就匆忙着手编写程序是许多软件开发工程失败的主要原因之一。&lt;/li&gt;
      &lt;li&gt;软件开发的过程是多人分工合作，分阶段完成的过程，参与人员之间的沟通和配合十分重要。但是，相当多的软件开发人员对软件的开发和维护存在不少错误的观念，在实践的过程中没有采用工程化的方法，或多或少采用了一些错误的方法和技术，这是造成软件危机的主要原因。&lt;/li&gt;
      &lt;li&gt;错误的认识和做法主要表现为忽视软件需求分析的重要性，认为软件开发就是写程序并设法使之运行，轻视软件维护等。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;软件开发与维护的方法不正确有关
    &lt;ol&gt;
      &lt;li&gt;只重视程序而忽视软件配置其余成分的糊涂观念。&lt;/li&gt;
      &lt;li&gt;在定义时期没有正确全面地理解用户需求，直到测试阶段或软件交付使用后才发现“已完成的”软件完全不符合用户需要。&lt;/li&gt;
      &lt;li&gt;严重的问题是在软件开发的不同阶段进行修改需要付出的代价是很不相同的&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;何为软件工程并稍深入讨论你对此概念的理解&quot;&gt;何为软件工程，并稍深入讨论你对此概念的理解&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;软件工程就是为了经济地获得可靠的且能在实际机器上有效地运行的软件，而建立和使用完善的工程原理。
——1968 年在第一届 NATO 会议上曾经给出了软件工程的一个早期定义&lt;/p&gt;

  &lt;p&gt;软件工程是：① 把系统的、规范的、可度量的途径应用于软件开发、运行和维护过程，也就是把工程应用于软件；② 研究 ① 中提到的途径。
——1993 年 IEEE 进一步给出了一个更全面更具体的定义&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;软件工程是运用工程的、数学的、计算机等科学概念、方法和原理来指导软件开发和管理和维护的一门学科。&lt;/p&gt;

&lt;h2 id=&quot;谈谈你对本课程的内容讲什么目标课程要求的理解&quot;&gt;谈谈你对本课程的内容（讲什么）、目标（课程要求）的理解&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;该课程讲授如何系统化、工程化、可量化的分析、设计、实现软件系统，旨在运用工程、数学、计算机等科学概念、方法和原理指导软件的实现和管理过程。课程以工程化模式（项目）驱动，每个学生都实质性的参与软件项目的分析、设计、编码、测试和维护。以提升学生的分析与设计能力、工程素养、团队协作精神、以及编程能力目标，此课程为后续的《系统分析与设计》、《本科毕业论文》重要的前序课程，此外，其将为成为一名合格的软件工程师奠定扎实的理论、技术及 IT 工程项目基础。
——教务系统上的课程内容简介&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我的理解是，软件工程这门课将会以理论和实践相结合的方式，引导我们&lt;strong&gt;科学地&lt;/strong&gt;实现软件开发的流程，课程要求我们能够了解并熟练运用课程中学到的知识到实际的软件开发中，成为一名合格的软件工程师。&lt;/p&gt;

&lt;h2 id=&quot;何为-uml&quot;&gt;何为 UML&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;The UML is the standard language for visualizing, specifying, constructing, and documenting the artifacts of a software-intensive system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;UML 是面向对象软件工程使用的统一建模语言，是一种图形化的语言，主要以图形方式表示。是一种开放的标准。&lt;/p&gt;

&lt;h2 id=&quot;结合一个例子分析建模生物四项基本原则&quot;&gt;结合一个例子分析建模生物四项基本原则&lt;/h2&gt;

&lt;p&gt;假设要建立一个企业职工信息管理系统。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;选择合适的模型：在需求分析时使用用例图可以更加快速地表达出要求&lt;/li&gt;
  &lt;li&gt;模型的精度对不同的对象是不一样：程序员使用的模型比对客户展示的模型更加复杂&lt;/li&gt;
  &lt;li&gt;模型与现实相一致：建立的模型需要完全贴合要求&lt;/li&gt;
  &lt;li&gt;同时建立多个模型：在需求分析、数据库建立中都会有不同的模型&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="软件工程理论与实践" /><summary type="html">什么是软件危机，结合软件危机的现象进行阐述</summary></entry><entry><title type="html">搭建自己的GitLab</title><link href="http://localhost:4000/_posts/2020-03-26-%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84GitLab/" rel="alternate" type="text/html" title="搭建自己的GitLab" /><published>2020-03-26T00:00:00+08:00</published><updated>2020-03-26T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84GitLab</id><content type="html" xml:base="http://localhost:4000/_posts/2020-03-26-%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84GitLab/">&lt;h2 id=&quot;实验环境&quot;&gt;实验环境&lt;/h2&gt;

&lt;p&gt;自己购买的 1C2G 腾讯云服务器。&lt;/p&gt;

&lt;p&gt;CentOS 7.6。&lt;/p&gt;

&lt;h2 id=&quot;实验过程&quot;&gt;实验过程&lt;/h2&gt;

&lt;p&gt;以下操作均在 root 账号下进行。&lt;/p&gt;

&lt;h3 id=&quot;修改宿主的-ssh-端口&quot;&gt;修改宿主的 SSH 端口&lt;/h3&gt;

&lt;p&gt;修改宿主的 SSH 端口，使用非 22  端口，这样以后从自建 gitlab 上拉取代码可以少费些功夫了。此外，管理用的宿主 SSH 端口改成别的也更安全。&lt;/p&gt;

&lt;p&gt;修改 SSHD 配置文件 &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;，将其中的  &lt;code&gt;#Port 22&lt;/code&gt; 去掉注释并改为其它端口号（比如我改成&lt;code&gt;Port 2222&lt;/code&gt;）。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;service sshd restart
semanage port -m -t ssh_port_t -p tcp 2222 # 未安装semanage可忽略
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;配置-swap-交换分区&quot;&gt;配置 SWAP 交换分区&lt;/h3&gt;

&lt;p&gt;由于 GitLab 较为消耗资源，我们需要先创建交换分区，以降低物理内存的压力。在实际生产环境中，如果服务器配置够高，则不必配置交换分区。（我 好 穷 啊&lt;/p&gt;

&lt;p&gt;新建 8 GB 大小的交换分区（一般来说 2 GB 就够了，可以自己改下面的大小）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;dd if=/dev/zero of=/root/swapfile bs=1M count=8192
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 SWAP 分区专用的格式化命令&lt;code&gt;mkswap&lt;/code&gt;，对新建的主分区进行格式化操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mkswap /root/swapfile
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;swapon /root/swapfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了能够让新的交换分区设备在重启后依然生效，需要将相关信息写入到配置文件中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;echo &quot;/root/swapfile swap swap defaults 0 0&quot; &amp;gt;&amp;gt; /etc/fstab
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;安装-docker&quot;&gt;安装 docker&lt;/h3&gt;

&lt;p&gt;参考 &lt;a href=&quot;https://www.runoob.com/docker/centos-docker-install.html&quot;&gt;CentOS Docker 安装&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;yum update -y
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum install -y docker-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行下面指令，拉取 gitlab 镜像并运行。为了方便日后备份维护，这里把三个重要的目录挂载进容器。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker pull gitlab/gitlab-ce
docker run \
    --detach \
    --hostname gitlab.wu-kan.cn \
    --name gitlab-ce \
    --restart always \
    --publish 443:443 \
    --publish 80:80 \
    --publish 22:22 \
    --volume /root/gitlab/etc/gitlab:/etc/gitlab \
    --volume /root/gitlab/var/log/gitlab:/var/log/gitlab \
    --volume /root/gitlab/var/opt/gitlab:/var/opt/gitlab \
    --env GITLAB_OMNIBUS_CONFIG=\
&quot;external_url 'https://gitlab.wu-kan.cn/'
letsencrypt['enable'] = true
letsencrypt['contact_emails'] = ['i@wu-kan.cn']
gitlab_pages['enable'] = true
pages_external_url 'http://gitlab-pages.wu-kan.cn/'&quot; \
    gitlab/gitlab-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行 &lt;code&gt;docker container ls&lt;/code&gt;，可以看到下面容器的状态是&lt;code&gt;(health: starting)&lt;/code&gt;。等这个状态变成 &lt;code&gt;(healthy)&lt;/code&gt; 时则说明已经部署完成，可以访问了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS                                 PORTS
                                                       NAMES
1a6c9c5ea464        gitlab/gitlab-ce    &quot;/assets/wrapper&quot;   About a minute ago   Up About a minute (health: starting)   0.0.0.0:22-&amp;gt;22/tcp, 0.0.0.0:80-&amp;gt;80/tcp, 0.0.0.0:443-&amp;gt;443/tcp   gitlab-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行的时候配置过低的话（比如我），会出现终端卡死。进入云服务商的监控页可以看到 CPU 和内存都是爆满的，建议喝一杯茶再回来看。&lt;/p&gt;

&lt;p&gt;如果持续出现 &lt;code&gt;unhealthy&lt;/code&gt; 的状态，可以考虑重启 docker 服务。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;service docker restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;gitlab-runner&quot;&gt;gitlab-runner&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker run \
    -d \
    --name gitlab-runner\
    --restart always \
    -v /root/gitlab-runner/etc/gitlab-runner:/etc/gitlab-runner \
    -v /root/gitlab-runner/var/run/docker.sock:/var/run/docker.sock \
    gitlab/gitlab-runner
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来进行注册操作。相关信息可以在&lt;a href=&quot;https://gitlab.wu-kan.cn/admin/runners&quot;&gt;https://gitlab.wu-kan.cn/admin/runners&lt;/a&gt;获取。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker exec -it gitlab-runner gitlab-runner register
&lt;/code&gt;&lt;/pre&gt;</content><author><name></name></author><category term="Linux" /><summary type="html">实验环境</summary></entry><entry><title type="html">写 CUDA 的一些小 Trick</title><link href="http://localhost:4000/_posts/2020-03-24-%E5%86%99-CUDA-%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F-Trick/" rel="alternate" type="text/html" title="写 CUDA 的一些小 Trick" /><published>2020-03-24T00:00:00+08:00</published><updated>2020-03-24T00:00:00+08:00</updated><id>http://localhost:4000/_posts/%E5%86%99%20CUDA%20%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%20Trick</id><content type="html" xml:base="http://localhost:4000/_posts/2020-03-24-%E5%86%99-CUDA-%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F-Trick/">&lt;p&gt;The art of doing more with less.&lt;/p&gt;

&lt;!-- slide --&gt;

&lt;h2 id=&quot;blockdim-griddim&quot;&gt;blockDim, gridDim&lt;/h2&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;第一次写 cuda 程序的时候，最让我抓狂的就是调用核函数时需要指定的这两个参数。&lt;/li&gt;
  &lt;li&gt;在对显卡硬件架构不熟悉的情况下，调参似乎是一种玄学，更是一种哲学。&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;blockdim-的经验值&quot;&gt;&lt;code&gt;blockDim&lt;/code&gt; 的经验值&lt;/h3&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;由于显卡是按照 STMD（多线程执行同一段代码）方式调度线程的，因此如果要充分利用调度资源，&lt;code&gt;blockDim&lt;/code&gt; 最好要是调度最小单位 Warp 的倍数。&lt;/li&gt;
  &lt;li&gt;目前主流的显卡单个 Warp 中都是 32 个线程，不排除未来会增加的可能。&lt;/li&gt;
  &lt;li&gt;以下是一些 &lt;code&gt;blockDim&lt;/code&gt; 的经验值，在大部分情况下都会有较优的表现。&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;dim3 block_dim_1(128); // 用于一维
dim3 block_dim_2(16, 16); // 用于二维
dim3 block_dim_3(8, 8, 8); // 用于三维
dim3 block_dim_v100(1024); // 让v100显卡满载；很多老显卡不支持，最多768个
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;cudaoccupancymaxpotentialblocksize&quot;&gt;&lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;从 CUDA 6.5 开始，提供了一个很有用的函数 &lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;，该函数定义在 &lt;code&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/code&gt;，接口及含义见代码中的注释。&lt;/p&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;template &amp;lt;class T&amp;gt;
cudaError_t __inline__ __host__ CUDART_DEVICE
cudaOccupancyMaxPotentialBlockSize(
    int *minGridSize,           // Suggested min grid size to achieve a full machine launch.
    int *blockSize,             // Suggested block size to achieve maximum occupancy.
    T func,                     // Kernel function.
    size_t dynamicSMemSize = 0, //Size of dynamically allocated shared memory. Of course, it is known at runtime before any kernel launch. The size of the statically allocated shared memory is not needed as it is inferred by the properties of func.
    int blockSizeLimit = 0)     //blockSizeLimit  = Maximum size for each block. In the case of 1D kernels, it can coincide with the number of input elements.
{
    return cudaOccupancyMaxPotentialBlockSizeVariableSMem(minGridSize, blockSize, func, __cudaOccupancyB2DHelper(dynamicSMemSize), blockSizeLimit);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;通过这个接口可以获得让 SM 占用率最大的 &lt;code&gt;blockDim&lt;/code&gt; 和对应的最小 &lt;code&gt;gridDim&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;可以不去关心各种硬件资源的限制写出低开销的调用&lt;/li&gt;
  &lt;li&gt;省去了自己调参数的过程&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;cudaoccupancymaxactiveblockspermultiprocessor&quot;&gt;&lt;code&gt;cudaOccupancyMaxActiveBlocksPerMultiprocessor&lt;/code&gt;&lt;/h3&gt;

&lt;h2 id=&quot;继续减少调度开销&quot;&gt;继续减少调度开销&lt;/h2&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;让我们以简单的复数拷贝为例。&lt;/li&gt;
  &lt;li&gt;看起来没什么可优化的？&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;void __global__ primitiveZcopy(
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	real_out[i] = real_in[i];
	imag_out[i] = imag_in[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;上述核函数中，启动多少线程就拷贝多少数据。&lt;/li&gt;
  &lt;li&gt;当启动参数不能恰好表示成两个数的乘积（&lt;code&gt;blockDim.x * gridDim.x&lt;/code&gt;）时，需要多次启动核函数
    &lt;ul&gt;
      &lt;li&gt;例如，对&lt;code&gt;19260817&lt;/code&gt;个数进行操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;更复杂的例子中可能不能通过多次启动核函数解决问题&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;减少核函数启动次数&quot;&gt;减少核函数启动次数&lt;/h3&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;void __global__ ifZcopy(
	const size_t n,
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
	const size_t i = blockDim.x * blockIdx.x + threadIdx.x;
	if (i &amp;lt; n)
	{
		real_out[i] = real_in[i];
		imag_out[i] = imag_in[i];
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;多启动几个线程就是了
    &lt;ul&gt;
      &lt;li&gt;CUDA 启动少量线程的开销非常小&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;需要套个&lt;code&gt;if&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;有什么缺点？&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;上述写法至少需要启动与元素数量相等的线程数。
    &lt;ul&gt;
      &lt;li&gt;不能使用&lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;返回的&lt;code&gt;gridDim&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;在对大量数据进行操作的时候，线程过多增加调度开销&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;将线程和对应的数据解耦&quot;&gt;将线程和对应的数据解耦&lt;/h3&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;void __global__ simpleZcopy(
	const size_t n,
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
	for (size_t i = blockDim.x * blockIdx.x + threadIdx.x;
		 i &amp;lt; n;
		 i += blockDim.x * gridDim.x)
	{
		real_out[i] = real_in[i];
		imag_out[i] = imag_in[i];
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;把&lt;code&gt;if&lt;/code&gt;改成&lt;code&gt;for&lt;/code&gt;，完美解决问题！
    &lt;ul&gt;
      &lt;li&gt;现在哪怕只启动一个线程，这个核函数也能返回正确结果，降低了依赖&lt;/li&gt;
      &lt;li&gt;配合&lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;效果极佳！&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;在与使用&lt;code&gt;#pragma omp parallel for&lt;/code&gt;并行的代码对比的时候，我们通常会发现，CUDA 版本少了外层的&lt;code&gt;for&lt;/code&gt;。
    &lt;ul&gt;
      &lt;li&gt;在这种写法下，爷的青春回来了！&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;有什么缺点？&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;虽然调度开销减少了，但是线程内部频繁&lt;code&gt;for&lt;/code&gt;跳转！&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;循环展开&quot;&gt;循环展开&lt;/h3&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;void __global__ simpleZcopy(
	const size_t n,
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
#pragma unroll(32)
	for (size_t i = blockDim.x * blockIdx.x + threadIdx.x;
		 i &amp;lt; n;
		 i += blockDim.x * gridDim.x)
	{
		real_out[i] = real_in[i];
		imag_out[i] = imag_in[i];
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;使用编译推导 &lt;code&gt;#pragma unroll(32)&lt;/code&gt; 将循环展开
    &lt;ul&gt;
      &lt;li&gt;奇怪的运行常数减少了！&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;有什么缺点？&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;又多了一个参数需要调！&lt;/li&gt;
  &lt;li&gt;需要循环次数是展开次数的倍数&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h3 id=&quot;使用-template-传递编译期常数&quot;&gt;使用 &lt;code&gt;template&lt;/code&gt; 传递编译期常数&lt;/h3&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;template&amp;lt;size_t UNROLL_SIZE&amp;gt;
void __global__ simpleZcopy(
	const size_t n,
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
#pragma unroll(UNROLL_SIZE)
	for (size_t i = blockDim.x * blockIdx.x + threadIdx.x;
		 i &amp;lt; n;
		 i += blockDim.x * gridDim.x)
	{
		real_out[i] = real_in[i];
		imag_out[i] = imag_in[i];
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;cuda 支持 cpp 语法，使用一些 cpp 语法糖！&lt;/li&gt;
  &lt;li&gt;将编译期就能确定的常数通过 template 传进去！
    &lt;ul&gt;
      &lt;li&gt;比 &lt;code&gt;#define&lt;/code&gt; 更优雅&lt;/li&gt;
      &lt;li&gt;方便生成不同展开的版本！&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;还可以传一些更有用的东西，比如 shared memory 数组的大小！&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;int numThreads, minGridSize, blockSize;
cudaOccupancyMaxPotentialBlockSize(
    &amp;amp;minGridSize,
    &amp;amp;blockSize,
    simpleZcopy&amp;lt;32&amp;gt;);
numThreads = minGridSize * blockSize;
if(n % numThreads == 0 &amp;amp;&amp;amp; n / numThreads % 32 == 0)
	simpleZcopy&amp;lt;32&amp;gt;&amp;lt;&amp;lt;&amp;lt;
		minGridSize,
		blockSize&amp;gt;&amp;gt;&amp;gt;(
		n,
		real_in,
		imag_in,
		real_out,
		imag_out);
else
	simpleZcopy&amp;lt;1&amp;gt;&amp;lt;&amp;lt;&amp;lt;
		minGridSize,
		blockSize&amp;gt;&amp;gt;&amp;gt;(
		n,
		real_in,
		imag_in,
		real_out,
		imag_out);
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;有什么缺点？&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;代码太丑了！&lt;/li&gt;
  &lt;li&gt;我就想简简单单拷贝一个数据&lt;/li&gt;
  &lt;li&gt;有必要这么麻烦吗&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h2 id=&quot;调库&quot;&gt;调库&lt;/h2&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;这种东西应该第一个讲
    &lt;ul&gt;
      &lt;li&gt;调库是一切优化的起点&lt;/li&gt;
      &lt;li&gt;调库是一切优化的终点&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;一些常见好用的高性能库，已经集成在 cuda toolkit 中
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;thrust&lt;/code&gt;中的 &lt;code&gt;thrust::copy&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;cublas_v2&lt;/code&gt;中的 &lt;code&gt;cublasDcopy&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;本例中甚至可以用 &lt;code&gt;cudaMemcpy&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide --&gt;

&lt;h2 id=&quot;减少-bank-conflict&quot;&gt;减少 Bank Conflict&lt;/h2&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;这是一个非常简单的分块矩阵乘法$A\times B =C$&lt;/li&gt;
  &lt;li&gt;为了访存对齐，$A$按照列优先的顺序存储&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;template &amp;lt;size_t BLOCK_SIZE&amp;gt;
void __global__ simpleMatMatMul(
	const float *Ac,
	const float *B,
	float *C,
	const size_t m,
	const size_t n,
	const size_t p)
{
	const size_t
		r = blockIdx.y * blockDim.y + threadIdx.y,
		c = blockIdx.x * blockDim.x + threadIdx.x;
	float res = 0;
	for (size_t t = 0; t &amp;lt; n; t += BLOCK_SIZE)
	{
		float __shared__
			sAc[BLOCK_SIZE][BLOCK_SIZE],
			sB[BLOCK_SIZE][BLOCK_SIZE];
		__syncthreads();
		sAc[threadIdx.y][threadIdx.x] = r &amp;lt; m &amp;amp;&amp;amp; t + threadIdx.x &amp;lt; n ? Ac[(t + threadIdx.x) * m + r] : 0;
		sB[threadIdx.x][threadIdx.y] = c &amp;lt; p &amp;amp;&amp;amp; t + threadIdx.y &amp;lt; n ? B[(t + threadIdx.y) * p + c] : 0;
		__syncthreads();
		for (size_t i = 0; i &amp;lt; blockDim.x; ++i)
			res += sAc[i][threadIdx.y] * sB[i][threadIdx.x];
	}
	if (r &amp;lt; m &amp;amp;&amp;amp; c &amp;lt; p)
		C[r * p + c] = res;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;有什么缺点？&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;GPU 共享内存是基于存储体切换的架构（bank-switched-architecture）。
    &lt;ul&gt;
      &lt;li&gt;在 Femi，Kepler，Maxwell 架构的设备上有 32 个存储体（也就是常说的共享内存分成 32 个 bank），而在 G200 与 G80 的硬件上只有 16 个存储体。&lt;/li&gt;
      &lt;li&gt;每个存储体（bank）每个周期只能指向一次操作（一个 32bit 的整数或者一个单精度的浮点型数据），一次读或者一次写，也就是说每个存储体（bank）的带宽为 每周期 32bit。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BLOCK_SIZE 通常是 32 的倍数，同一列的线程访问对应的 Share Memory 访问同一个 bank 的不同地址，发生大量 bank conflict！&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- slide vertical=true --&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;template &amp;lt;size_t BLOCK_SIZE&amp;gt;
void __global__ naiveMatMatMul(
	const float *Ac,
	const float *B,
	float *C,
	const size_t m,
	const size_t n,
	const size_t p)
{
	const size_t
		r = blockIdx.y * blockDim.y + threadIdx.y,
		c = blockIdx.x * blockDim.x + threadIdx.x;
	float res = 0;
	for (size_t t = 0; t &amp;lt; n; t += BLOCK_SIZE)
	{
		float __shared__
			sAc[BLOCK_SIZE][BLOCK_SIZE | 1],
			sB[BLOCK_SIZE][BLOCK_SIZE | 1];
		__syncthreads();
		sAc[threadIdx.y][threadIdx.x] = r &amp;lt; m &amp;amp;&amp;amp; t + threadIdx.x &amp;lt; n ? Ac[(t + threadIdx.x) * m + r] : 0;
		sB[threadIdx.x][threadIdx.y] = c &amp;lt; p &amp;amp;&amp;amp; t + threadIdx.y &amp;lt; n ? B[(t + threadIdx.y) * p + c] : 0;
		__syncthreads();
		for (size_t i = 0; i &amp;lt; blockDim.x; ++i)
			res += sAc[i][threadIdx.y] * sB[i][threadIdx.x];
	}
	if (r &amp;lt; m &amp;amp;&amp;amp; c &amp;lt; p)
		C[r * p + c] = res;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- slide vertical=true --&gt;

&lt;ul&gt;
  &lt;li&gt;Shared Memory 二维数组每一行增加一个偏移位，解决问题！&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="高性能计算" /><summary type="html">The art of doing more with less.</summary></entry><entry><title type="html">CUDA内存拷贝竞速</title><link href="http://localhost:4000/_posts/2020-03-23-CUDA%E6%8B%B7%E8%B4%9D%E7%AB%9E%E9%80%9F/" rel="alternate" type="text/html" title="CUDA内存拷贝竞速" /><published>2020-03-23T00:00:00+08:00</published><updated>2020-03-23T00:00:00+08:00</updated><id>http://localhost:4000/_posts/CUDA%E6%8B%B7%E8%B4%9D%E7%AB%9E%E9%80%9F</id><content type="html" xml:base="http://localhost:4000/_posts/2020-03-23-CUDA%E6%8B%B7%E8%B4%9D%E7%AB%9E%E9%80%9F/">&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;

&lt;p&gt;近期在做一个 CUDA 相关库的优化，发现稍作一点修改（下文中 &lt;code&gt;simpleZcopy&lt;/code&gt; 到 &lt;code&gt;naiveZcopy&lt;/code&gt; 的修改）后就让运行时间在 16 秒左右的仿真过程快了将近 1 秒。猜想这个优化方法可能是非常通用的，于是单独做一次实验来验证猜想。&lt;/p&gt;

&lt;p&gt;本文在显卡上双精度复数拷贝的场景进行试验，同时和一些常见的高性能拷贝 API 做性能对比。&lt;/p&gt;

&lt;h2 id=&quot;实验环境&quot;&gt;实验环境&lt;/h2&gt;

&lt;p&gt;使用 v100 集群上一个结点的单张 v100 运行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ nvdia-smi
Mon Dec  2 08:38:49 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0    24W / 250W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;实验过程与分析&quot;&gt;实验过程与分析&lt;/h2&gt;

&lt;h3 id=&quot;一些说明&quot;&gt;一些说明&lt;/h3&gt;

&lt;h4 id=&quot;内存管理&quot;&gt;内存管理&lt;/h4&gt;

&lt;p&gt;我使用的显卡是 Tesla V100，单卡显存为 16130MiB。为简化代码，我用 &lt;code&gt;&amp;lt;thrust/device_vector.h&amp;gt;&lt;/code&gt; 库创建了四个大小为$2^{28}$的向量用于双精度复数输入和输出。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;const size_t
    n = 1 &amp;lt;&amp;lt; 28;
thrust::device_vector&amp;lt;double&amp;gt;
    real_in(n, 1),
    imag_in(n, 1),
    real_out(n),
    imag_out(n);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和 &lt;code&gt;cudaMalloc&lt;/code&gt; 分配的显存空间相比，&lt;code&gt;thrust::device_vector&amp;lt;double&amp;gt;&lt;/code&gt; 的开销在本例中可以忽略。&lt;/p&gt;

&lt;h4 id=&quot;计时方式&quot;&gt;计时方式&lt;/h4&gt;

&lt;p&gt;为简化代码，写了这样一个结构体用于各部分的计时，离开代码块的时候自动输出运行时间。通过调用 &lt;code&gt;cudaEventElapsedTime&lt;/code&gt; 实现线程安全的计时。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;struct WuKTimer
{
    cudaEvent_t beg, end;
    WuKTimer()
    {
        cudaEventCreate(&amp;amp;beg);
        cudaEventCreate(&amp;amp;end);
        cudaEventRecord(beg);
    }
    ~WuKTimer()
    {
        cudaEventRecord(end);
        cudaEventSynchronize(beg);
        cudaEventSynchronize(end);
        float elapsed_time;
        cudaEventElapsedTime(
            &amp;amp;elapsed_time,
            beg,
            end);
        printf(&quot;%f\n&quot;, elapsed_time);
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;cudaoccupancymaxpotentialblocksize&quot;&gt;&lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;从 CUDA 6.5 开始，提供了一个很有用的函数 &lt;code&gt;cudaOccupancyMaxPotentialBlockSize&lt;/code&gt;，该函数定义在 &lt;code&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/code&gt;，接口及含义见下面的注释。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;template &amp;lt;class T&amp;gt;
cudaError_t __inline__ __host__ CUDART_DEVICE
cudaOccupancyMaxPotentialBlockSize(
    int *minGridSize,           // Suggested min grid size to achieve a full machine launch.
    int *blockSize,             // Suggested block size to achieve maximum occupancy.
    T func,                     // Kernel function.
    size_t dynamicSMemSize = 0, //Size of dynamically allocated shared memory. Of course, it is known at runtime before any kernel launch. The size of the statically allocated shared memory is not needed as it is inferred by the properties of func.
    int blockSizeLimit = 0)     //blockSizeLimit  = Maximum size for each block. In the case of 1D kernels, it can coincide with the number of input elements.
{
    return cudaOccupancyMaxPotentialBlockSizeVariableSMem(minGridSize, blockSize, func, __cudaOccupancyB2DHelper(dynamicSMemSize), blockSizeLimit);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个接口可以获得在 SM 占用率最大时 &lt;code&gt;blockDim&lt;/code&gt; 和对应的最小 &lt;code&gt;gridDim&lt;/code&gt; ，这样就可以不去关心各种硬件资源的限制写出低开销的调用，同时也省去了自己调参数的过程。&lt;/p&gt;

&lt;p&gt;唯一遗憾的是，这个函数获得的值是在运行时而非编译时确定的。也就是说，有时候需要通过 template 参数传 BlockDim 的大小来让编译器做一些优化时（如循环展开，再比如 Shared Memory 的大小），要通过&lt;code&gt;switch&lt;/code&gt;语句，略显繁琐。&lt;/p&gt;

&lt;h3 id=&quot;simplezcopy&quot;&gt;&lt;code&gt;simpleZcopy&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;先来做最基础的算法优化版本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;void __global__ simpleZcopy(
	const size_t n,
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
	for (size_t i = threadIdx.x + blockDim.x * blockIdx.x;
		 i &amp;lt; n;
		 i += blockDim.x * gridDim.x)
	{
		real_out[i] = real_in[i];
		imag_out[i] = imag_in[i];
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行时间为 12.118016ms。&lt;/p&gt;

&lt;h3 id=&quot;naivezcopy&quot;&gt;&lt;code&gt;naiveZcopy&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;在 &lt;code&gt;simpleZcopy&lt;/code&gt; 基础上，把读操作和写操作分离开。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;void __global__ naiveZcopy(
	const size_t n,
	const double *real_in,
	const double *imag_in,
	double *real_out,
	double *imag_out)
{
	for (size_t i = blockIdx.x * blockDim.x + threadIdx.x;
		 i &amp;lt; n;
		 i += blockDim.x * gridDim.x)
	{
		const double
			real = real_in[i],
			imag = imag_in[i];
		real_out[i] = real;
		imag_out[i] = imag;
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行时间为 12.254208ms。&lt;/p&gt;

&lt;h3 id=&quot;cudamemcpy&quot;&gt;&lt;code&gt;cudaMemcpy&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;直接使用 cuda 提供的内存拷贝接口实现，分别拷贝实部和虚部。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;cudaMemcpy(
    thrust::raw_pointer_cast(real_out.data()),
    thrust::raw_pointer_cast(real_in.data()),
    sizeof(double) * n,
    cudaMemcpyDeviceToDevice);
cudaMemcpy(
    thrust::raw_pointer_cast(imag_out.data()),
    thrust::raw_pointer_cast(imag_in.data()),
    sizeof(double) * n,
    cudaMemcpyDeviceToDevice);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行时间为 11.898560ms。&lt;/p&gt;

&lt;h3 id=&quot;cublasdcopy&quot;&gt;&lt;code&gt;cublasDcopy&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;使用 cublas 库中提供的第一级向量操作接口实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;cublasDcopy(
    wk_cublas_handle,
    n,
    thrust::raw_pointer_cast(real_in.data()),
    1,
    thrust::raw_pointer_cast(real_out.data()),
    1);
cublasDcopy(
    wk_cublas_handle,
    n,
    thrust::raw_pointer_cast(imag_in.data()),
    1,
    thrust::raw_pointer_cast(imag_out.data()),
    1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行时间为 12.208064ms，更慢了。&lt;/p&gt;

&lt;h3 id=&quot;thrustcopy&quot;&gt;&lt;code&gt;thrust::copy&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;thrust::copy(
    real_in.begin(),
    real_in.end(),
    real_out.begin());
thrust::copy(
    imag_in.begin(),
    imag_in.end(),
    imag_out.begin());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行时间 11.536608ms。&lt;/p&gt;

&lt;h3 id=&quot;thrustdevice_vectordoubleoperator&quot;&gt;&lt;code&gt;thrust::device_vector&amp;lt;double&amp;gt;::operator=&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;我们是使用 &lt;code&gt;thrust::device_vector&amp;lt;double&amp;gt;&lt;/code&gt; 进行内存管理的，我们也可以直接调用它的拷贝赋值函数。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;real_out = real_in;
imag_out = imag_in;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行时间 11.528096ms，和前一个差不多。&lt;/p&gt;

&lt;h2 id=&quot;源代码&quot;&gt;源代码&lt;/h2&gt;

&lt;h3 id=&quot;zcopypbs&quot;&gt;&lt;code&gt;Zcopy.pbs&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;调度脚本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;#PBS -N Zcopy
#PBS -l nodes=1:ppn=32:gpus=1
#PBS -j oe
#PBS -q gpu
source /public/software/profile.d/cuda10.0.sh
cd $PBS_O_WORKDIR
nvcc Zcopy.cu -run -lcublas
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;zcopyo18921&quot;&gt;&lt;code&gt;Zcopy.o18921&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;运行结果，自上而下分别是 &lt;code&gt;simpleZcopy&lt;/code&gt;、&lt;code&gt;naiveZcopy&lt;/code&gt;、&lt;code&gt;cudaMemcpy&lt;/code&gt;、&lt;code&gt;cublasDcopy&lt;/code&gt;、&lt;code&gt;thrust::copy&lt;/code&gt;、&lt;code&gt;thrust::device_vector&amp;lt;double&amp;gt;::operator=&lt;/code&gt; 的运行时间。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;12.118016
12.254208
11.898560
12.208064
11.536608
11.528096
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;zcopycu&quot;&gt;&lt;code&gt;Zcopy.cu&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;cuda_runtime.h&amp;gt;
#include &amp;lt;thrust/device_vector.h&amp;gt;
#include &amp;lt;thrust/copy.h&amp;gt;
#include &amp;lt;cublas_v2.h&amp;gt;
void __global__ simpleZcopy(
    const size_t n,
    const double *real_in,
    const double *imag_in,
    double *real_out,
    double *imag_out)
{
    for (size_t i = threadIdx.x + blockDim.x * blockIdx.x;
         i &amp;lt; n;
         i += blockDim.x * gridDim.x)
    {
        real_out[i] = real_in[i];
        imag_out[i] = imag_in[i];
    }
}
void __global__ naiveZcopy(
    const size_t n,
    const double *real_in,
    const double *imag_in,
    double *real_out,
    double *imag_out)
{
    for (size_t i = blockIdx.x * blockDim.x + threadIdx.x;
         i &amp;lt; n;
         i += blockDim.x * gridDim.x)
    {
        const double
            real = real_in[i],
            imag = imag_in[i];
        real_out[i] = real;
        imag_out[i] = imag;
    }
}
struct WuKTimer
{
    cudaEvent_t beg, end;
    WuKTimer()
    {
        cudaEventCreate(&amp;amp;beg);
        cudaEventCreate(&amp;amp;end);
        cudaEventRecord(beg);
    }
    ~WuKTimer()
    {
        cudaEventRecord(end);
        cudaEventSynchronize(beg);
        cudaEventSynchronize(end);
        float elapsed_time;
        cudaEventElapsedTime(
            &amp;amp;elapsed_time,
            beg,
            end);
        printf(&quot;%f\n&quot;, elapsed_time);
    }
};
const size_t
    n = 1 &amp;lt;&amp;lt; 28;
thrust::device_vector&amp;lt;double&amp;gt;
    real_in(n, 1),
    imag_in(n, 1),
    real_out(n),
    imag_out(n);
int main()
{
    {
        WuKTimer wk_timer;
        int minGridSize, blockSize;
        cudaOccupancyMaxPotentialBlockSize(
            &amp;amp;minGridSize,
            &amp;amp;blockSize,
            simpleZcopy);
        simpleZcopy&amp;lt;&amp;lt;&amp;lt;
            minGridSize,
            blockSize&amp;gt;&amp;gt;&amp;gt;(
            n,
            thrust::raw_pointer_cast(real_in.data()),
            thrust::raw_pointer_cast(imag_in.data()),
            thrust::raw_pointer_cast(real_out.data()),
            thrust::raw_pointer_cast(imag_out.data()));
    }
    {
        WuKTimer wk_timer;
        int minGridSize, blockSize;
        cudaOccupancyMaxPotentialBlockSize(
            &amp;amp;minGridSize,
            &amp;amp;blockSize,
            naiveZcopy);
        naiveZcopy&amp;lt;&amp;lt;&amp;lt;
            minGridSize,
            blockSize&amp;gt;&amp;gt;&amp;gt;(
            n,
            thrust::raw_pointer_cast(real_in.data()),
            thrust::raw_pointer_cast(imag_in.data()),
            thrust::raw_pointer_cast(real_out.data()),
            thrust::raw_pointer_cast(imag_out.data()));
    }
    {
        WuKTimer wk_timer;
        cudaMemcpy(
            thrust::raw_pointer_cast(real_out.data()),
            thrust::raw_pointer_cast(real_in.data()),
            sizeof(double) * n,
            cudaMemcpyDeviceToDevice);
        cudaMemcpy(
            thrust::raw_pointer_cast(imag_out.data()),
            thrust::raw_pointer_cast(imag_in.data()),
            sizeof(double) * n,
            cudaMemcpyDeviceToDevice);
    }
    cublasHandle_t wk_cublas_handle;
    cublasCreate(&amp;amp;wk_cublas_handle);
    {
        WuKTimer wk_timer;
        cublasDcopy(
            wk_cublas_handle,
            n,
            thrust::raw_pointer_cast(real_in.data()),
            1,
            thrust::raw_pointer_cast(real_out.data()),
            1);
        cublasDcopy(
            wk_cublas_handle,
            n,
            thrust::raw_pointer_cast(imag_in.data()),
            1,
            thrust::raw_pointer_cast(imag_out.data()),
            1);
    }
    cublasDestroy(wk_cublas_handle);
    {
        WuKTimer wk_timer;
        thrust::copy(
            real_in.begin(),
            real_in.end(),
            real_out.begin());
        thrust::copy(
            imag_in.begin(),
            imag_in.end(),
            imag_out.begin());
    }
    {
        WuKTimer wk_timer;
        real_out = real_in;
        imag_out = imag_in;
    }
}
&lt;/code&gt;&lt;/pre&gt;</content><author><name></name></author><category term="高性能计算" /><summary type="html">简介</summary></entry></feed>